@Article{colesMultilabTestFacial2022,
  title = {A Multi-Lab Test of the Facial Feedback Hypothesis by the {{Many Smiles Collaboration}}},
  author = {Nicholas A. Coles and David S. March and Fernando Marmolejo-Ramos and Jeff T. Larsen and Nwadiogo C. Arinze and Izuchukwu L. G. Ndukaihe and Megan L. Willis and Francesco Foroni and Niv Reggev and Aviv Mokady and Patrick S. Forscher and John F. Hunter and Gwena{\"e}l Kaminski and Elif Y{\"u}vr{\"u}k and Aycan Kapucu and Tam{\a'a}s Nagy and Nandor Hajdu and Julian Tejada and Raquel M. K. Freitag and Danilo Zambrano and Bidisha Som and Balazs Aczel and Krystian Barzykowski and Sylwia Adamus and Katarzyna Filip and Yuki Yamada and Ayumi Ikeda and Daniel L. Eaves and Carmel A. Levitan and Sydney Leiweke and Michal Parzuchowski and Natalie Butcher and Gerit Pfuhl and Dana M. Basnight-Brown and Jos{\a'e} A. Hinojosa and Pedro R. Montoro and Lady G. {Javela D} and Kevin Vezirian and Hans IJzerman and Natalia Trujillo and Sarah D. Pressman and Pascal M. Gygax and Asil A. {\"O}zdo{\u g}ru and Susana Ruiz-Fernandez and Phoebe C. Ellsworth and Lowell Gaertner and Fritz Strack and Marco Marozzi and Marco Tullio Liuzza},
  date = {2022-10-20},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  issn = {2397-3374},
  doi = {10.1038/s41562-022-01458-9},
  url = {https://www.nature.com/articles/s41562-022-01458-9},
  urldate = {2022-10-25},
  langid = {english},
}
@Article{strackInhibitingFacilitatingConditions1988,
  title = {Inhibiting and Facilitating Conditions of the Human Smile: {{A}} Nonobtrusive Test of the Facial Feedback Hypothesis},
  shorttitle = {Inhibiting and Facilitating Conditions of the Human Smile},
  author = {Fritz Strack and Leonard L. Martin and Sabine Stepper},
  date = {1988},
  journaltitle = {Journal of Personality and Social Psychology},
  volume = {54},
  pages = {768--777},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.54.5.768},
  abstract = {We investigated the hypothesis that people's facial activity influences their affective responses. Two studies were designed to both eliminate methodological problems of earlier experiments and clarify theoretical ambiguities. This was achieved by having subjects hold a pen in their mouth in ways that either inhibited or facilitated the muscles typically associated with smiling without requiring subjects to pose in a smiling face. Study 1's results demonstrated the effectiveness of the procedure. Subjects reported more intense humor responses when cartoons were presented under facilitating conditions than under inhibiting conditions that precluded labeling of the facial expression in emotion categories. Study 2 served to further validate the methodology and to answer additional theoretical questions. The results replicated Study 1's findings and also showed that facial feedback operates on the affective but not on the cognitive component of the humor response. Finally, the results suggested that both inhibitory and facilitatory mechanisms may have contributed to the observed affective responses. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Emotional Responses,Humor,Smiles},
}
@Article{wagenmakersRegisteredReplicationReport2016,
  title = {Registered {{Replication Report}}: {{Strack}}, {{Martin}}, \& {{Stepper}} (1988)},
  shorttitle = {Registered {{Replication Report}}},
  author = {E.-J. Wagenmakers and T. Beek and L. Dijkhoff and Q. F. Gronau and A. Acosta and R. B. Adams and D. N. Albohn and E. S. Allard and S. D. Benning and E.-M. Blouin-Hudon and L. C. Bulnes and T. L. Caldwell and R. J. Calin-Jageman and C. A. Capaldi and N. S. Carfagno and K. T. Chasten and A. Cleeremans and L. Connell and J. M. DeCicco and K. Dijkstra and A. H. Fischer and F. Foroni and U. Hess and K. J. Holmes and J. L. H. Jones and O. Klein and C. Koch and S. Korb and P. Lewinski and J. D. Liao and S. Lund and J. Lupianez and D. Lynott and C. N. Nance and S. Oosterwijk and A. A. Ozdo{\u g}ru and A. P. Pacheco-Unguetti and B. Pearson and C. Powis and S. Riding and T.-A. Roberts and R. I. Rumiati and M. Senden and N. B. Shea-Shumsky and K. Sobocko and J. A. Soto and T. G. Steiner and J. M. Talarico and Z. M. {van Allen} and M. Vandekerckhove and B. Wainwright and J. F. Wayand and R. Zeelenberg and E. E. Zetzer and R. A. Zwaan},
  options = {useprefix=true},
  date = {2016-11-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {11},
  number = {6},
  pages = {917--928},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691616674458},
  url = {https://doi.org/10.1177/1745691616674458},
  urldate = {2022-10-25},
  abstract = {According to the facial feedback hypothesis, people?s affective responses can be influenced by their own facial expression (e.g., smiling, pouting), even when their expression did not result from their emotional experiences. For example, Strack, Martin, and Stepper (1988) instructed participants to rate the funniness of cartoons using a pen that they held in their mouth. In line with the facial feedback hypothesis, when participants held the pen with their teeth (inducing a ?smile?), they rated the cartoons as funnier than when they held the pen with their lips (inducing a ?pout?). This seminal study of the facial feedback hypothesis has not been replicated directly. This Registered Replication Report describes the results of 17 independent direct replications of Study 1 from Strack et al. (1988), all of which followed the same vetted protocol. A meta-analysis of these studies examined the difference in funniness ratings between the ?smile? and ?pout? conditions. The original Strack et al. (1988) study reported a rating difference of 0.82 units on a 10-point Likert scale. Our meta-analysis revealed a rating difference of 0.03 units with a 95\% confidence interval ranging from ?0.11 to 0.16.},
  langid = {english},
}


@Article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian Multilevel Modeling}} with the {{R Package}} Brms},
  author = {Paul-Christian B{\"u}rkner},
  date = {2018},
  journaltitle = {The R Journal},
  volume = {10},
  number = {1},
  pages = {395--411},
  issn = {2073-4859},
  url = {https://journal.r-project.org/archive/2018/RJ-2018-017/index.html},
  urldate = {2019-03-25},
  langid = {english},
}

@Article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  author = {Paul-Christian B{\"u}rkner},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  keywords = {Statistics},
  annotation = {00000},
}

@Article{burknerOrdinalRegressionModels2019,
  ids = {BurknerOrdinalRegressionModels2019},
  title = {Ordinal {{Regression Models}} in {{Psychology}}: {{A Tutorial}}},
  shorttitle = {Ordinal {{Regression Models}} in {{Psychology}}},
  author = {Paul-Christian B{\"u}rkner and Matti Vuorre},
  date = {2019-03-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {1},
  pages = {77--101},
  issn = {2515-2459},
  doi = {10.1177/2515245918823199},
  url = {https://doi.org/10.1177/2515245918823199},
  urldate = {2019-12-02},
  abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
  langid = {english},
}

@Article{liddellAnalyzingOrdinalData2018,
  title = {Analyzing Ordinal Data with Metric Models: {{What}} Could Possibly Go Wrong?},
  shorttitle = {Analyzing Ordinal Data with Metric Models},
  author = {Torrin M. Liddell and John K. Kruschke},
  date = {2018-11-01},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {79},
  pages = {328--348},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2018.08.009},
  url = {http://www.sciencedirect.com/science/article/pii/S0022103117307746},
  urldate = {2018-10-15},
  abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term “Likert,” and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems — false alarms, misses, and inversions — for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
  keywords = {Bayesian analysis,Likert,Ordered-probit,Ordinal data},
}

@Software{rcoreteamLanguageEnvironmentStatistical2021,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}. {{Version}} 4.1.1},
  author = {{R Core Team}},
  date = {2021},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}},
  keywords = {\#nosource},
}

@Software{standevelopmentteamStanModelingLanguage2021,
  title = {Stan {{Modeling Language Users Guide}} and {{Reference Manual}}, Version 2.28.},
  author = {Stan Development Team},
  date = {2021},
  url = {https://mc-stan.org},
  keywords = {\#nosource},
}
@Article{batesFittingLinearMixedEffects2015,
  title = {Fitting {{Linear Mixed-Effects Models Using}} Lme4},
  author = {Douglas M. Bates and Martin M{\"a}chler and Ben M. Bolker and Steve Walker},
  date = {2015},
  journaltitle = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
  keywords = {\#nosource,Statistics},
  annotation = {00014},
}

@Software{batesLme4LinearMixedEffects2022,
  title = {Lme4: {{Linear Mixed-Effects Models}} Using '{{Eigen}}' and {{S4}}},
  shorttitle = {Lme4},
  author = {Douglas M. Bates and Martin M{\"a}chler and Ben M. Bolker and Steven Walker and Rune Haubo Bojesen Christensen and Henrik Singmann and Bin Dai and Fabian Scheipl and Gabor Grothendieck and Peter Green and John Fox and Alexander Bauer and Pavel N. Krivitsky (shared {copyright on simulate.formula)}},
  date = {2022-07-08},
  url = {https://CRAN.R-project.org/package=lme4},
  urldate = {2022-10-25},
  abstract = {Fit linear and generalized linear mixed-effects models. The models and their components are represented using S4 classes and methods. The core computational algorithms are implemented using the 'Eigen' C++ library for numerical linear algebra and 'RcppEigen' "glue".},
  version = {1.1-30},
  keywords = {Econometrics,Environmetrics,MixedModels,Psychometrics,SpatioTemporal},
}
@Article{juddTreatingStimuliRandom2012,
  title = {Treating Stimuli as a Random Factor in Social Psychology: {{A}} New and Comprehensive Solution to a Pervasive but Largely Ignored Problem},
  shorttitle = {Treating Stimuli as a Random Factor in Social Psychology},
  author = {Charles M. Judd and Jacob Westfall and David A. Kenny},
  date = {2012},
  journaltitle = {Journal of Personality and Social Psychology},
  volume = {103},
  number = {1},
  pages = {54--69},
  issn = {1939-1315 0022-3514},
  doi = {10.1037/a0028347},
  abstract = {Throughout social and cognitive psychology, participants are routinely asked to respond in some way to experimental stimuli that are thought to represent categories of theoretical interest. For instance, in measures of implicit attitudes, participants are primed with pictures of specific African American and White stimulus persons sampled in some way from possible stimuli that might have been used. Yet seldom is the sampling of stimuli taken into account in the analysis of the resulting data, in spite of numerous warnings about the perils of ignoring stimulus variation (Clark, 1973; Kenny, 1985; Wells \& Windschitl, 1999). Part of this failure to attend to stimulus variation is due to the demands imposed by traditional analysis of variance procedures for the analysis of data when both participants and stimuli are treated as random factors. In this article, we present a comprehensive solution using mixed models for the analysis of data with crossed random factors (e.g., participants and stimuli). We show the substantial biases inherent in analyses that ignore one or the other of the random factors, and we illustrate the substantial advantages of the mixed models approach with both hypothetical and actual, well-known data sets in social psychology (Bem, 2011; Blair, Chapleau, \& Judd, 2005; Correll, Park, Judd, \& Wittenbrink, 2002).},
  langid = {english},
  keywords = {Models,Sampling,Social Psychology,Statistics,Stimulus presentation},
  annotation = {00243},
}
@Book{gelmanDataAnalysisUsing2007,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Andrew Gelman and Jennifer Hill},
  date = {2007},
  publisher = {{Cambridge University Press}},
  location = {{New York, NY}},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout. Author resource page: http://www.stat.columbia.edu/\textasciitilde gelman/arm/},
  isbn = {978-0-521-68689-1},
  langid = {english},
  pagetotal = {654},
  keywords = {Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Regression Analysis,Political Science / General,Psychology / Assessment; Testing & Measurement,Statistics},
  annotation = {00058},
}

@Article{harmon-jonesDiscreteEmotionsQuestionnaire2016,
  title = {The {{Discrete Emotions Questionnaire}}: {{A New Tool}} for {{Measuring State Self-Reported Emotions}}},
  shorttitle = {The {{Discrete Emotions Questionnaire}}},
  author = {Cindy Harmon-Jones and Brock Bastian and Eddie Harmon-Jones},
  date = {2016-08-08},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {11},
  number = {8},
  pages = {e0159915},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0159915},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0159915},
  urldate = {2022-11-04},
  abstract = {Several discrete emotions have broad theoretical and empirical importance, as shown by converging evidence from diverse areas of psychology, including facial displays, developmental behaviors, and neuroscience. However, the measurement of these states has not progressed along with theory, such that when researchers measure subjectively experienced emotions, they commonly rely on scales assessing broad dimensions of affect (positivity and negativity), rather than discrete emotions. The current manuscript presents four studies that validate a new instrument, the Discrete Emotions Questionnaire (DEQ), that is sensitive to eight distinct state emotions: anger, disgust, fear, anxiety, sadness, happiness, relaxation, and desire. Emotion theory supporting the importance of distinguishing these specific emotions is reviewed.},
  langid = {english},
  keywords = {Anxiety,Eigenvalues,Emotions,Factor analysis,Fear,Happiness,Psychometrics,Relaxation (psychology)},
}
