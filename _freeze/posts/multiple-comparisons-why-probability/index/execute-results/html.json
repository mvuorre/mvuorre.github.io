{
  "hash": "720ba761faa3f1189cce2aef6789e77e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Help bayes help you: The case of multiple contrasts\"\ndate: 2024-03-01\ncategories:\n  - R\n  - statistics\n  - bayes\nexecute:\n  cache: true\n  message: false\n  warning: false\ndraft: true\nfrom: markdown+emoji\nreference-location: margin\nexecute-dir: file\nformat:\n  html:\n    code-fold: show\n    code-summary: \"Code\"\n    df-print: kable\nbibliography: references.bib\nimage: \"images/jerry-bayes.png\"\n---\n\n\n\nA while ago I saw something on social media that upset me. (No surprises there.) In response, I probably said things that upset other people. As result of all that upset, in this blog post I address the following question: **Are there everyday run-of-the-mill topics in which we can easily show that bayes---using the rules of probability to integrate information in data and elsewhere to produce more accurate information---reigns supreme over clever ad hoc devices for controlling error rates over hypotheticals**?\n\nI'm not going to say anything new here. The basic ideas are very well known and communicated e.g. in [baseball example james stein] and [gelman multiple comparisons]. What I am going to try is to examine how well those true and tested ideas can apply in typical experimental psychology situations.\n\nLet us consider an everyday ANOVA application: You took some chickens and randomly allocated them to different diets at birth.[^1] After a couple of weeks, you measured each chicken's weight to determine which kind of diet leads to the fattest chickens. I show these data in @fig-1. Sounds like a no-brainer for an ANOVA: Is there a difference in the group means?\n\n[^1]: See `?chickwts`: \"Newly hatched chicks were randomly allocated into six groups, and each group was given a different feed supplement. Their weights in grams after six weeks are given along with feed types.\" This is not a typical psychology study but the data was easier for me to find than a multiple-groups humans dataset. Let us say that the ideas discussed here generalize directly from chickens to humans.\n\nA clean experiment typically produces perhaps two to four means of assumed gaussian distributions. For such clean designs, statistical details might not matter because analysts can produce plots that visualize the means and differneces therein--with appropriate representations for uncertainty--and numbers end up being less important. Since in debates about the usefulness of bayes, one can typically fall back to this \"whatever 2x2 design yolo!\" argument, I want to provide some kind of an illustration of how bayes reigns supreme even in those simple situations.\n\nThe issue essentially boils down to a topic typically discussed under the umbrella term of *multiple comparisons* and how one should *adjust* for it assuming different kinds of scenarios in which other hypothetical experiments might be run.\n\nTo get started \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggstance)\nlibrary(ggbeeswarm)\nlibrary(emmeans)\nlibrary(afex)\nlibrary(brms)\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# I take a smaller subset of feeds for simplicity\nset.seed(1010)\ndat <- chickwts |> \n  # filter(feed %in% sample(unique(feed), 3)) |> \n  mutate(feed = fct_reorder(feed, weight)) |> \n  arrange(feed) |> \n  rowid_to_column() |> \n  tibble()\ndat_avg <- dat |> \n  summarise(\n    mean_cl_normal(weight),\n    n = n(),\n    .by = feed\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  ggplot(aes(feed, weight)) +\n  stat_summary() +\n  geom_point(\n    position = position_quasirandom(width = .1),\n    shape = 1\n  )\n```\n\n::: {.cell-output-display}\n![The individual chicken weights (empty points) and the group means and standard errors (filled points).](index_files/figure-html/fig-1-1.png){#fig-1 width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- aov_ez(\n  dv = \"weight\", \n  between = \"feed\",\n  id = \"rowid\",\n  data = dat\n)\n\n\n\nx <- tibble(\n  adjustment = c(\"tukey\", \"scheffe\", \"sidak\", \"bonferroni\", \"dunnettx\", \"mvt\", \"none\")\n) |> \n  mutate(\n    contrast = map(\n      adjustment,\n      ~emmeans(fit, ~feed) |> \n        contrast(\"trt.vs.ctrl\", adjust = .x) |> \n        summary(infer = TRUE)\n    )\n  )\n\nx |> \n  slice(-1) |> # This is illegal outside pairwise comparisons\n  unnest(contrast) |> \n  ggplot(aes(p.value, contrast, col = adjustment)) +\n  scale_x_log10() +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nx |> \n  unnest(contrast) |> \n  mutate(\n    contrast = fct_reorder(contrast, estimate),\n    adjustment = fct_reorder(adjustment, upper.CL-lower.CL)\n  ) |> \n  ggplot(aes(estimate, contrast, col = adjustment, shape = p.value < 0.05)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_shape_manual(values = c(21, 19)) +\n  guides(\n    shape = \"none\",\n    color = guide_legend(reverse = TRUE)\n  ) +\n  geom_pointrangeh(\n    aes(xmin = lower.CL, xmax = upper.CL),\n    fill = \"white\",\n    position = position_dodgev(.5)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- brm(\n  weight ~ 1 + (1 | feed),\n  data = dat,\n  cores = 4,\n  file = \"brm-model\"\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidybayes)\nfit %>%\n  spread_draws(r_feed[condition,]) %>%\n  compare_levels(r_feed, by = condition, comparison = emmeans_comparison(\"trt.vs.ctrl\")) %>%\n  mean_qi()\n  ungroup() %>%\n  mutate(condition = reorder(condition, r_feed)) %>%\n  ggplot(aes(y = condition, x = r_feed)) +\n  stat_halfeye() +\n  geom_vline(xintercept = 0, linetype = \"dashed\") \n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}