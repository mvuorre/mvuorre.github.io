@article{ahmedFutureAcademicPublishing2023,
  title = {The Future of Academic Publishing},
  author = {Ahmed, Abubakari and Al-Khatib, Aceil and Boum, Yap and Debat, Humberto and Gurmendi Dunkelberg, Alonso and Hinchliffe, Lisa Janicke and Jarrad, Frith and Mastroianni, Adam and Mineault, Patrick and Pennington, Charlotte R. and Pruszynski, J. Andrew},
  date = {2023-07-13},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  pages = {1--6},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-023-01637-2},
  url = {https://www.nature.com/articles/s41562-023-01637-2},
  urldate = {2023-07-19},
  abstract = {Academic publishing is the backbone of science dissemination ---- but is the current system fit for purpose? We asked a diverse group of scientists to comment on the future of publishing. They discuss systemic issues, challenges, and opportunities, and share their vision for the future.},
  langid = {english},
  keywords = {Behavioral Sciences,Experimental Psychology,general,Life Sciences,Microeconomics,Neurosciences,Personality and Social Psychology},
  file = {/Users/matti/Zotero/storage/8YIDBNDZ/Ahmed et al_2023_The future of academic publishing.pdf}
}

@online{aleksicOpenSciencePeer2015,
  title = {An {{Open Science Peer Review Oath}}},
  author = {Aleksic, Jelena and Alexa, Adrian and Attwood, Teresa K. and Hong, Neil Chue and Dahl\"o, Martin and Davey, Robert and Dinkel, Holger and F\"orstner, Konrad U. and Grigorov, Ivo and H\'erich\'e, Jean-Karim and Lahti, Leo and MacLean, Dan and Markie, Michael L. and Molloy, Jenny and Schneider, Maria Victoria and Scott, Camille and Smith-Unna, Richard and Vieira, Bruno Miguel and Workshop, as part of the AllBio: Open Science \& Reproducibility Best Practice},
  date = {2015-01-09},
  number = {3:271},
  eprint = {3:271},
  eprinttype = {F1000Research},
  doi = {10.12688/f1000research.5686.2},
  url = {https://f1000research.com/articles/3-271},
  urldate = {2025-02-03},
  abstract = {One of the foundations of the scientific method is to be able to reproduce experiments and corroborate the results of research that has been done before. However, with the increasing complexities of new technologies and techniques, coupled with the specialisation of experiments, reproducing research findings has become a growing challenge. Clearly, scientific methods must be conveyed succinctly, and with clarity and rigour, in order for research to be reproducible. Here, we propose steps to help increase the transparency of the scientific method and the reproducibility of research results: specifically, we introduce a peer-review oath and accompanying manifesto. These have been designed to offer guidelines to enable reviewers (with the minimum friction or bias) to follow and apply open science principles, and support the ideas of transparency, reproducibility and ultimately greater societal impact. Introducing the oath and manifesto at the stage of peer review will help to check that the research being published includes everything that other researchers would need to successfully repeat the work. Peer review is the lynchpin of the publishing system: encouraging the community to consciously (and conscientiously) uphold these principles should help to improve published papers, increase confidence in the reproducibility of the work and, ultimately, provide strategic benefits to authors and their institutions.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/matti/Zotero/storage/B5J8DBAF/aleksic-etal_2015_F1000Research.pdf}
}

@article{eisenImplementingPublishThen2020,
  title = {Implementing a "Publish, Then Review" Model of Publishing},
  author = {Eisen, Michael B and Akhmanova, Anna and Behrens, Timothy E and Harper, Diane M and Weigel, Detlef and Zaidi, Mone},
  date = {2020-12-01},
  journaltitle = {eLife},
  volume = {9},
  pages = {e64910},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.64910},
  url = {https://doi.org/10.7554/eLife.64910},
  urldate = {2025-02-03},
  abstract = {From July 2021 eLife will only review manuscripts already published as preprints, and will focus its editorial process on producing public reviews to be posted alongside the preprints.},
  keywords = {peer review,preprints,research assessment,research communication,scientific publishing},
  file = {/Users/matti/Zotero/storage/KFTALHVG/eisen-etal_2020_elife.pdf}
}

@online{holcombeScientistsWhatAre2025,
  title = {Scientists! {{What}} Are You Supporting?},
  author = {Holcombe, Alex O.},
  date = {2025-01-31T10:32:14+00:00},
  url = {https://alexholcombe.wordpress.com/2025/01/31/scientists-what-are-you-supporting/},
  urldate = {2025-02-03},
  abstract = {Much has been said about how expensive academic journals are. Large companies like Elsevier, Sage, Springer Nature, Taylor \& Francis, and Wiley publish most of the major journals, and their sha\dots},
  langid = {english},
  organization = {Alex Holcombe's blog}
}

@article{kathawallaEasingOpenScience2021,
  title = {Easing {{Into Open Science}}: {{A Guide}} for {{Graduate Students}} and {{Their Advisors}}},
  shorttitle = {Easing {{Into Open Science}}},
  author = {Kathawalla, Ummul-Kiram and Silverstein, Priya and Syed, Moin},
  editor = {Wetzel, Eunike},
  date = {2021-01-26},
  journaltitle = {Collabra: Psychology},
  shortjournal = {Collabra: Psychology},
  volume = {7},
  number = {1},
  pages = {18684},
  issn = {2474-7394},
  doi = {10.1525/collabra.18684},
  url = {https://doi.org/10.1525/collabra.18684},
  urldate = {2025-02-03},
  abstract = {This article provides a roadmap to assist graduate students and their advisors to engage in open science practices. We suggest eight open science practices that novice graduate students could begin adopting today. The topics we cover include journal clubs, project workflow, preprints, reproducible code, data sharing, transparent writing, preregistration, and registered reports. To address concerns about not knowing how to engage in open science practices, we provide a difficulty rating of each behavior (easy, medium, difficult), present them in order of suggested adoption, and follow the format of what, why, how, and worries. We give graduate students ideas on how to approach conversations with their advisors/collaborators, ideas on how to integrate open science practices within the graduate school framework, and specific resources on how to engage with each behavior. We emphasize that engaging in open science behaviors need not be an all or nothing approach, but rather graduate students can engage with any number of the behaviors outlined.},
  file = {/Users/matti/Zotero/storage/DZ55LQM4/kathawalla-etal_2021_collabra-psychology.pdf}
}

@article{kriegeskorteOpenEvaluationVision2012,
  title = {Open {{Evaluation}}: {{A Vision}} for {{Entirely Transparent Post-Publication Peer Review}} and {{Rating}} for {{Science}}},
  shorttitle = {Open {{Evaluation}}},
  author = {Kriegeskorte, Nikolaus},
  date = {2012},
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front. Comput. Neurosci.},
  volume = {6},
  issn = {1662-5188},
  doi = {10.3389/fncom.2012.00079},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2012.00079/full#h9},
  urldate = {2017-11-20},
  abstract = {The two major functions of a scientific publishing system are to provide access to and evaluation of scientific papers. While open access (OA) is becoming a reality, open evaluation (OE), the other side of coin, has received less attention. Evaluation steers the attention of the scientific community and thus the very course of science. It also influences the use of scientific findings in public policy. The current system of scientific publishing provides only journal prestige as an indication of the quality of new papers and relies on a non-transparent and noisy pre-publication peer review process, which delays publication by many months on average. Here I propose an OE system, in which papers are evaluated post-publication in an ongoing fashion by means of open peer review and rating. Through signed ratings and reviews, scientists steer the attention of their field and build their reputation. Reviewers are motivated to be objective, because low-quality or self-serving signed evaluations will negatively impact their reputation. A core feature of this proposal is a division of powers between the accumulation of evaluative evidence and the analysis of this evidence by paper evaluation functions (PEFs). PEFs can be freely defined by individuals or groups (e.g. scientific societies) and provide a plurality of perspectives on the scientific literature. Simple PEFs will use averages of ratings, weighting reviewers (e.g. by H-factor) and rating scales (e.g. by relevance to a decision process) in different ways. Complex PEFs will use advanced statistical techniques to infer the quality of a paper. Papers with initially promising ratings will be more deeply evaluated. The continual refinement of PEFs in response to attempts by individuals to influence evaluations in their own favor will make the system ungameable. OA and OE together have the power to revolutionize scientific publishing and usher in a new culture of transparency, constructive criticism, and collaboration.},
  langid = {english},
  keywords = {nosource,open evaluation,Open science,Peer Review,Publishing,ratings,social web},
  file = {/Users/matti/Zotero/storage/SEI3TWBP/kriegeskorte_2012_open_evaluation.pdf}
}

@article{moreyPeerReviewersOpenness2016,
  title = {The {{Peer Reviewers Openness Initiative}}: Incentivizing Open Research Practices through Peer Review},
  shorttitle = {The {{Peer Reviewers9 Openness Initiative}}},
  author = {Morey, Richard D. and Chambers, Christopher D. and Etchells, Peter J. and Harris, Christine R. and Hoekstra, Rink and Lakens, Dani\"el and Lewandowsky, Stephan and Morey, Candice Coker and Newman, Daniel P. and Sch\"onbrodt, Felix D. and Vanpaemel, Wolf and Wagenmakers, Eric-Jan and Zwaan, Rolf A.},
  date = {2016-01-01},
  journaltitle = {Royal Society Open Science},
  volume = {3},
  number = {1},
  pages = {150547},
  issn = {2054-5703},
  doi = {10.1098/rsos.150547},
  url = {http://rsos.royalsocietypublishing.org/content/3/1/150547},
  urldate = {2017-07-27},
  abstract = {Openness is one of the central values of science. Open scientific practices such as sharing data, materials and analysis scripts alongside published articles have many benefits, including easier replication and extension studies, increased availability of data for theory-building and meta-analysis, and increased possibility of review and collaboration even after a paper has been published. Although modern information technology makes sharing easier than ever before, uptake of open practices had been slow. We suggest this might be in part due to a social dilemma arising from misaligned incentives and propose a specific, concrete mechanism---reviewers withholding comprehensive review---to achieve the goal of creating the expectation of open practices as a matter of scientific principle.},
  langid = {english},
  keywords = {open research,peer review,reproducibility,science,transparency},
  annotation = {00039},
  file = {/Users/matti/Zotero/storage/LL2CJTKQ/morey_et_al_2016_the_peer_reviewers_openness_initiative.pdf}
}

@article{moshontzGuidePostingManaging2021,
  title = {A {{Guide}} to {{Posting}} and {{Managing Preprints}}},
  author = {Moshontz, Hannah and Binion, Grace and Walton, Haley and Brown, Benjamin T. and Syed, Moin},
  date = {2021-04-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {2},
  pages = {25152459211019948},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/25152459211019948},
  url = {https://doi.org/10.1177/25152459211019948},
  urldate = {2024-06-19},
  abstract = {Posting preprints online allows psychological scientists to get feedback, speed dissemination, and ensure public access to their work. This guide is designed to help psychological scientists post preprints and manage them across the publication pipeline. We review terminology, provide a historical and legal overview of preprints, and give guidance on posting and managing preprints before, during, or after the peer-review process to achieve different aims (e.g., get feedback, speed dissemination, achieve open access). We offer concrete recommendations to authors, such as post preprints that are complete and carefully proofread; post preprints in a dedicated preprint server that assigns DOIs, provides editable metadata, is indexed by GoogleScholar, supports review and endorsements, and supports version control; include a draft date and information about the paper's status on the cover page; license preprints with CC BY licenses that permit public use with attribution; and keep preprints up to date after major revisions. Although our focus is on preprints (unpublished versions of a work), we also offer information relevant to postprints (author-formatted, post-peer-review versions of a work) and work that will not otherwise be published (e.g., theses and dissertations).},
  langid = {english},
  file = {/Users/matti/Zotero/storage/EZKXRUDV/Moshontz et al_2021_A Guide to Posting and Managing Preprints.pdf}
}

@article{severBiomedicalPublishingHistoric2023,
  title = {Biomedical Publishing: {{Past}} Historic, Present Continuous, Future Conditional},
  shorttitle = {Biomedical Publishing},
  author = {Sever, Richard},
  date = {2023-10-03},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {21},
  number = {10},
  pages = {e3002234},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3002234},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002234},
  urldate = {2023-10-08},
  abstract = {Academic journals have been publishing the results of biomedical research for more than 350 years. Reviewing their history reveals that the ways in which journals vet submissions have changed over time, culminating in the relatively recent appearance of the current peer-review process. Journal brand and Impact Factor have meanwhile become quality proxies that are widely used to filter articles and evaluate scientists in a hypercompetitive prestige economy. The Web created the potential for a more decoupled publishing system in which articles are initially disseminated by preprint servers and then undergo evaluation elsewhere. To build this future, we must first understand the roles journals currently play and consider what types of content screening and review are necessary and for which papers. A new, open ecosystem involving preprint servers, journals, independent content-vetting initiatives, and curation services could provide more multidimensional signals for papers and avoid the current conflation of trust, quality, and impact. Academia should strive to avoid the alternative scenario, however, in which stratified publisher silos lock in submissions and simply perpetuate this conflation.},
  langid = {english},
  keywords = {Bibliometrics,Internet,Medical journals,Open access publishing,Peer review,Publication ethics,Scientific publishing,Scientists},
  file = {/Users/matti/Zotero/storage/G7YVJ632/Sever_2023_Biomedical publishing.pdf}
}

@article{silversteinGuideSocialScience2024,
  title = {A Guide for Social Science Journal Editors on Easing into Open Science},
  author = {Silverstein, Priya and Elman, Colin and Montoya, Amanda and McGillivray, Barbara and Pennington, Charlotte R. and Harrison, Chase H. and Steltenpohl, Crystal N. and R\"oer, Jan Philipp and Corker, Katherine S. and Charron, Lisa M. and Elsherif, Mahmoud and Malicki, Mario and Hayes-Harb, Rachel and Grinschgl, Sandra and Neal, Tess and Evans, Thomas Rhys and Karhulahti, Veli-Matti and Krenzer, William L. D. and Belaus, Anabel and Moreau, David and Burin, Debora I. and Chin, Elizabeth and Plomp, Esther and Mayo-Wilson, Evan and Lyle, Jared and Adler, Jonathan M. and Bottesini, Julia G. and Lawson, Katherine M. and Schmidt, Kathleen and Reneau, Kyrani and Vilhuber, Lars and Waltman, Ludo and Gernsbacher, Morton Ann and Plonski, Paul E. and Ghai, Sakshi and Grant, Sean and Christian, Thu-Mai and Ngiam, William and Syed, Moin},
  date = {2024-02-16},
  journaltitle = {Research Integrity and Peer Review},
  shortjournal = {Res Integr Peer Rev},
  volume = {9},
  number = {1},
  pages = {2},
  issn = {2058-8615},
  doi = {10.1186/s41073-023-00141-5},
  url = {https://doi.org/10.1186/s41073-023-00141-5},
  urldate = {2025-02-03},
  abstract = {Journal editors have a large amount of power to advance open science in their respective fields by incentivising and mandating open policies and practices at their journals. The Data PASS Journal Editors Discussion Interface (JEDI, an online community for social science journal editors: www.dpjedi.org) has collated several resources on embedding open science in journal editing (www.dpjedi.org/resources). However, it can be overwhelming as an editor new to open science practices to know where to start. For this reason, we created a guide for journal editors on how to get started with open science. The guide outlines steps that editors can take to implement open policies and practices within their journal, and goes through the what, why, how, and worries of each policy and practice. This manuscript introduces and summarizes the guide (full guide: https://doi.org/10.31219/osf.io/hstcx).},
  langid = {english},
  keywords = {Journal editing,Open science,Peer review,Scholarly publishing},
  file = {/Users/matti/Zotero/storage/6Z8GJ2SD/silverstein-etal_2024_research-integrity-and-peer-review.pdf}
}

@article{syedValuingPreprintsMust2024,
  title = {Valuing {{Preprints Must}} Be {{Part}} of {{Responsible Research Assessment}}},
  author = {Syed, Moin},
  date = {2024-03-17},
  journaltitle = {Meta-Psychology},
  volume = {8},
  issn = {2003-2714},
  doi = {10.15626/MP.2023.3758},
  url = {https://open.lnu.se/index.php/metapsychology/article/view/3758},
  urldate = {2024-06-19},
  abstract = {Comments on papers by Sch\"onbrodt et al. (2022) and G\"artner et al. (2022) proposing reforms to the research assessment process. Given the prominent role of preprints in contemporary scientific practice, they must be an accepted and central component of research assessment.},
  langid = {english},
  keywords = {DORA,meta-psychology,open science,preprints,research assessment},
  file = {/Users/matti/Zotero/storage/ZIXRAM6P/Syed_2024_Valuing Preprints Must be Part of Responsible Research Assessment.pdf}
}
