
@article{LiuReviewComparisonBayesian2018,
	title = {A review and comparison of {Bayesian} and likelihood-based inferences in beta regression and zero-or-one-inflated beta regression},
	volume = {27},
	issn = {0962-2802},
	url = {https://doi.org/10.1177/0962280216650699},
	doi = {10.1177/0962280216650699},
	abstract = {Beta regression is an increasingly popular statistical technique in medical research for modeling of outcomes that assume values in (0, 1), such as proportions and patient reported outcomes. When outcomes take values in the intervals [0,1), (0,1], or [0,1], zero-or-one-inflated beta (zoib) regression can be used. We provide a thorough review on beta regression and zoib regression in the modeling, inferential, and computational aspects via the likelihood-based and Bayesian approaches. We demonstrate the statistical and practical importance of correctly modeling the inflation at zero/one rather than ad hoc replacing them with values close to zero/one via simulation studies; the latter approach can lead to biased estimates and invalid inferences. We show via simulation studies that the likelihood-based approach is computationally faster in general than MCMC algorithms used in the Bayesian inferences, but runs the risk of non-convergence, large biases, and sensitivity to starting values in the optimization algorithm especially with clustered/correlated data, data with sparse inflation at zero and one, and data that warrant regularization of the likelihood. The disadvantages of the regular likelihood-based approach make the Bayesian approach an attractive alternative in these cases. Software packages and tools for fitting beta and zoib regressions in both the likelihood-based and Bayesian frameworks are also reviewed.},
	language = {en},
	number = {4},
	urldate = {2019-02-20},
	journal = {Statistical Methods in Medical Research},
	author = {Liu, Fang and Eugenio, Evercita C},
	month = apr,
	year = {2018},
	pages = {1024--1044},
	file = {Liu_Eugenio_2018_A review and comparison of Bayesian and likelihood-based inferences in beta.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\YQXYA8YG\\Liu_Eugenio_2018_A review and comparison of Bayesian and likelihood-based inferences in beta.pdf:application/pdf},
}

@article{FerrariBetaRegressionModelling2004,
	title = {Beta {Regression} for {Modelling} {Rates} and {Proportions}},
	volume = {31},
	issn = {0266-4763},
	url = {https://doi.org/10.1080/0266476042000214501},
	doi = {10.1080/0266476042000214501},
	abstract = {This paper proposes a regression model where the response is beta distributed using a parameterization of the beta law that is indexed by mean and dispersion parameters. The proposed model is useful for situations where the variable of interest is continuous and restricted to the interval (0, 1) and is related to other variables through a regression structure. The regression parameters of the beta regression model are interpretable in terms of the mean of the response and, when the logit link is used, of an odds ratio, unlike the parameters of a linear regression that employs a transformed response. Estimation is performed by maximum likelihood. We provide closed-form expressions for the score function, for Fisher's information matrix and its inverse. Hypothesis testing is performed using approximations obtained from the asymptotic normality of the maximum likelihood estimator. Some diagnostic measures are introduced. Finally, practical applications that employ real data are presented and discussed.},
	number = {7},
	urldate = {2019-02-20},
	journal = {Journal of Applied Statistics},
	author = {Ferrari, Silvia and Cribari-Neto, Francisco},
	month = aug,
	year = {2004},
	keywords = {Beta Distribution, Leverage, Maximum Likelihood Estimation, Proportions, Residuals},
	pages = {799--815},
	file = {Ferrari_Cribari-Neto_2004_Beta Regression for Modelling Rates and Proportions.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\ZAT65J3M\\Ferrari_Cribari-Neto_2004_Beta Regression for Modelling Rates and Proportions.pdf:application/pdf},
}

@article{LiuZoibPackageBayesian2015,
	title = {zoib: {An} {R} {Package} for {Bayesian} {Inference} for {Beta} {Regression} and {Zero}/{One} {Inflated} {Beta} {Regression}},
	volume = {7},
	issn = {2073-4859},
	shorttitle = {zoib},
	url = {https://journal.r-project.org/archive/2015/RJ-2015-019/index.html},
	language = {en},
	number = {2},
	urldate = {2019-01-31},
	journal = {The R Journal},
	author = {Liu, Fang and Kong, Yunchuan},
	year = {2015},
	pages = {34--51},
	file = {Liu_Kong_2015_zoib.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\XUPMSMVP\\Liu_Kong_2015_zoib.pdf:application/pdf},
}

@article{SmithsonBetterLemonSqueezer2006,
	title = {A better lemon squeezer? {Maximum}-likelihood regression with beta-distributed dependent variables.},
	volume = {11},
	issn = {1939-1463(Electronic),1082-989X(Print)},
	doi = {10.1037/1082-989X.11.1.54},
	abstract = {Uncorrectable skew and heteroscedasticity are among the "lemons" of psychological data, yet many important variables naturally exhibit these properties. For scales with a lower and upper bound, a suitable candidate for models is the beta distribution, which is very flexible and models skew quite well. The authors present maximum-likelihood regression models assuming that the dependent variable is conditionally beta distributed rather than Gaussian. The approach models both means (location) and variances (dispersion) with their own distinct sets of predictors (continuous and/or categorical), thereby modeling heteroscedasticity. The location submodel link function is the logit and thereby analogous to logistic regression, whereas the dispersion submodel is log linear. Real examples show that these models handle the independent observations case readily. The article discusses comparisons between beta regression and alternative techniques, model selection and interpretation, practical estimation, and software. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Methods},
	author = {Smithson, Michael and Verkuilen, Jay},
	year = {2006},
	keywords = {*Frequency Distribution, *Maximum Likelihood, *Psychometrics, *Statistical Regression, *Statistical Variables, Models, Skewed Distribution},
	pages = {54--71},
	file = {Smithson_Verkuilen_2006_A better lemon squeezer.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\HUWE7UZ2\\Smithson_Verkuilen_2006_A better lemon squeezer.pdf:application/pdf},
}

@article{OspinaInflatedBetaDistributions2008,
	title = {Inflated beta distributions},
	volume = {51},
	issn = {1613-9798},
	url = {https://doi.org/10.1007/s00362-008-0125-4},
	doi = {10.1007/s00362-008-0125-4},
	abstract = {This paper considers the issue of modeling fractional data observed on [0,1), (0,1] or [0,1]. Mixed continuous-discrete distributions are proposed. The beta distribution is used to describe the continuous component of the model since its density can have quite different shapes depending on the values of the two parameters that index the distribution. Properties of the proposed distributions are examined. Also, estimation based on maximum likelihood and conditional moments is discussed. Finally, practical applications that employ real data are presented.},
	language = {en},
	number = {1},
	urldate = {2018-12-06},
	journal = {Statistical Papers},
	author = {Ospina, Raydonal and Ferrari, Silvia L. P.},
	month = mar,
	year = {2008},
	keywords = {Proportions, Beta distribution, Conditional moments, Fractional data, Inflated beta distribution, Maximum likelihood estimation, Mixture},
	pages = {111},
	file = {Ospina_Ferrari_2008_Inflated beta distributions.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\3VG3NCN9\\Ospina_Ferrari_2008_Inflated beta distributions.pdf:application/pdf},
}

@article{LiddellAnalyzingOrdinalData2018,
	title = {Analyzing ordinal data with metric models: {What} could possibly go wrong?},
	volume = {79},
	issn = {0022-1031},
	shorttitle = {Analyzing ordinal data with metric models},
	url = {http://www.sciencedirect.com/science/article/pii/S0022103117307746},
	doi = {10.1016/j.jesp.2018.08.009},
	abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term “Likert,” and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems — false alarms, misses, and inversions — for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
	urldate = {2018-10-15},
	journal = {Journal of Experimental Social Psychology},
	author = {Liddell, Torrin M. and Kruschke, John K.},
	month = nov,
	year = {2018},
	keywords = {Likert, Bayesian analysis, Ordered-probit, Ordinal data},
	pages = {328--348},
	file = {Liddell_Kruschke_2018_Analyzing ordinal data with metric models.pdf:C\:\\Users\\cpuk\\Dropbox\\ZoteroPDF\\Liddell_Kruschke_2018_Analyzing ordinal data with metric models.pdf:application/pdf},
}

@article{BurknerBrmsPackageBayesian2017,
	title = {brms: {An} {R} {Package} for {Bayesian} {Multilevel} {Models} {Using} {Stan}},
	volume = {80},
	doi = {10.18637/jss.v080.i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Bürkner, Paul-Christian},
	year = {2017},
	note = {00000},
	keywords = {Statistics},
	pages = {1--28},
	file = {Bürkner_2017_brms.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\9TBKPU6G\\Bürkner_2017_brms.pdf:application/pdf},
}

@article{VerkuilenMixedMixtureRegression2012,
	title = {Mixed and {Mixture} {Regression} {Models} for {Continuous} {Bounded} {Responses} {Using} the {Beta} {Distribution}},
	volume = {37},
	issn = {1076-9986, 1935-1054},
	url = {http://jeb.sagepub.com/content/37/1/82},
	doi = {10.3102/1076998610396895},
	abstract = {Doubly bounded continuous data are common in the social and behavioral sciences. Examples include judged probabilities, confidence ratings, derived proportions such as percent time on task, and bounded scale scores. Dependent variables of this kind are often difficult to analyze using normal theory models because their distributions may be quite poorly modeled by the normal distribution. The authors extend the beta-distributed generalized linear model (GLM) proposed in Smithson and Verkuilen (2006) to discrete and continuous mixtures of beta distributions, which enables modeling dependent data structures commonly found in real settings. The authors discuss estimation using both deterministic marginal maximum likelihood and stochastic Markov chain Monte Carlo (MCMC) methods. The results are illustrated using three data sets from cognitive psychology experiments.},
	language = {en},
	number = {1},
	urldate = {2015-08-17},
	journal = {Journal of Educational and Behavioral Statistics},
	author = {Verkuilen, Jay and Smithson, Michael},
	month = feb,
	year = {2012},
	note = {00000},
	keywords = {Statistics, mixture model, beta distribution, general linear model, mixed model},
	pages = {82--113},
	file = {Verkuilen_Smithson_2012_Mixed and Mixture Regression Models for Continuous Bounded Responses Using the.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\7TVCJRK2\\Verkuilen_Smithson_2012_Mixed and Mixture Regression Models for Continuous Bounded Responses Using the.pdf:application/pdf},
}

@article{BurknerOrdinalRegressionModels2019,
	title = {Ordinal {Regression} {Models} in {Psychology}: {A} {Tutorial}},
	volume = {2},
	copyright = {All rights reserved},
	issn = {2515-2459},
	shorttitle = {Ordinal {Regression} {Models} in {Psychology}},
	url = {https://doi.org/10.1177/2515245918823199},
	doi = {10.1177/2515245918823199},
	abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Bürkner, Paul-Christian and Vuorre, Matti},
	month = mar,
	year = {2019},
	pages = {77--101},
	file = {Bürkner_Vuorre_2019_Ordinal Regression Models in Psychology.pdf:C\:\\Users\\cpuk\\Dropbox\\ZoteroPDF\\Bürkner_Vuorre_2019_Ordinal Regression Models in Psychology.pdf:application/pdf},
}

@article{YarkoniChoosingPredictionExplanation2017,
	title = {Choosing {Prediction} {Over} {Explanation} in {Psychology}: {Lessons} {From} {Machine} {Learning}},
	volume = {12},
	issn = {1745-6916},
	shorttitle = {Choosing {Prediction} {Over} {Explanation} in {Psychology}},
	url = {https://doi.org/10.1177/1745691617693393},
	doi = {10.1177/1745691617693393},
	abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology’s near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
	language = {en},
	number = {6},
	urldate = {2018-08-31},
	journal = {Perspectives on Psychological Science},
	author = {Yarkoni, Tal and Westfall, Jacob},
	month = nov,
	year = {2017},
	pages = {1100--1122},
	file = {Yarkoni_Westfall_2017_Choosing Prediction Over Explanation in Psychology.pdf:C\:\\Users\\cpuk\\Zotero\\storage\\6PBPEDUL\\Yarkoni_Westfall_2017_Choosing Prediction Over Explanation in Psychology.pdf:application/pdf},
}
@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2020},
  url = {https://www.R-project.org/},
}
@Article{R-brms_a,
  title = {{brms}: An {R} Package for {Bayesian} Multilevel Models Using {Stan}},
  author = {Paul-Christian Bürkner},
  journal = {Journal of Statistical Software},
  year = {2017},
  volume = {80},
  number = {1},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  encoding = {UTF-8},
}
@Article{R-brms_b,
  title = {Advanced {Bayesian} Multilevel Modeling with the {R} Package {brms}},
  author = {Paul-Christian Bürkner},
  journal = {The R Journal},
  year = {2018},
  volume = {10},
  number = {1},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017},
  encoding = {UTF-8},
}
@Manual{R-broom,
  title = {broom: Convert Statistical Objects into Tidy Tibbles},
  author = {David Robinson and Alex Hayes and Simon Couch},
  year = {2021},
  note = {https://broom.tidymodels.org/, https://github.com/tidymodels/broom},
}
@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller},
  year = {2021},
  note = {R package version 1.0.4},
  url = {https://CRAN.R-project.org/package=dplyr},
}
@Manual{R-extraDistr,
  title = {extraDistr: Additional Univariate and Multivariate Distributions},
  author = {Tymoteusz Wolodzko},
  year = {2020},
  note = {R package version 1.9.1},
  url = {https://CRAN.R-project.org/package=extraDistr},
}
@Manual{R-forcats,
  title = {forcats: Tools for Working with Categorical Variables (Factors)},
  author = {Hadley Wickham},
  year = {2021},
  note = {R package version 0.5.1},
  url = {https://CRAN.R-project.org/package=forcats},
}
@Manual{R-ggbeeswarm,
  title = {ggbeeswarm: Categorical Scatter (Violin Point) Plots},
  author = {Erik Clarke and Scott Sherrill-Mix},
  year = {2017},
  note = {R package version 0.6.0},
  url = {https://CRAN.R-project.org/package=ggbeeswarm},
}
@Book{R-ggplot2,
  author = {Hadley Wickham},
  title = {ggplot2: Elegant Graphics for Data Analysis},
  publisher = {Springer-Verlag New York},
  year = {2016},
  isbn = {978-3-319-24277-4},
  url = {https://ggplot2.tidyverse.org},
}
@Manual{R-glue,
  title = {glue: Interpreted String Literals},
  author = {Jim Hester},
  year = {2020},
  note = {R package version 1.4.2},
  url = {https://CRAN.R-project.org/package=glue},
}
@Book{R-knitr,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {https://yihui.org/knitr/},
}
@Manual{R-patchwork,
  title = {patchwork: The Composer of Plots},
  author = {Thomas Lin Pedersen},
  year = {2020},
  note = {R package version 1.1.1},
  url = {https://CRAN.R-project.org/package=patchwork},
}
@Manual{R-purrr,
  title = {purrr: Functional Programming Tools},
  author = {Lionel Henry and Hadley Wickham},
  year = {2020},
  note = {R package version 0.3.4},
  url = {https://CRAN.R-project.org/package=purrr},
}
@Article{R-Rcpp_a,
  title = {{Rcpp}: Seamless {R} and {C++} Integration},
  author = {Dirk Eddelbuettel and Romain Fran\c{c}ois},
  journal = {Journal of Statistical Software},
  year = {2011},
  volume = {40},
  number = {8},
  pages = {1--18},
  url = {https://www.jstatsoft.org/v40/i08/},
  doi = {10.18637/jss.v040.i08},
}
@Article{R-Rcpp_b,
  title = {{Extending 	extit{R} with 	extit{C++}: A Brief Introduction to 	extit{Rcpp}}},
  author = {Dirk Eddelbuettel and James Joseph Balamuta},
  journal = {The American Statistician},
  year = {2018},
  volume = {72},
  number = {1},
  pages = {28-36},
  url = {https://doi.org/10.1080/00031305.2017.1375990},
  doi = {10.1080/00031305.2017.1375990},
}
@Manual{R-readr,
  title = {readr: Read Rectangular Text Data},
  author = {Hadley Wickham and Jim Hester},
  year = {2020},
  note = {R package version 1.4.0},
  url = {https://CRAN.R-project.org/package=readr},
}
@Manual{R-scales,
  title = {scales: Scale Functions for Visualization},
  author = {Hadley Wickham and Dana Seidel},
  year = {2020},
  note = {R package version 1.1.1},
  url = {https://CRAN.R-project.org/package=scales},
}
@Manual{R-stringr,
  title = {stringr: Simple, Consistent Wrappers for Common String Operations},
  author = {Hadley Wickham},
  year = {2019},
  note = {R package version 1.4.0},
  url = {https://CRAN.R-project.org/package=stringr},
}
@Manual{R-tibble,
  title = {tibble: Simple Data Frames},
  author = {Kirill Müller and Hadley Wickham},
  year = {2021},
  note = {R package version 3.1.0},
  url = {https://CRAN.R-project.org/package=tibble},
}
@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham},
  year = {2021},
  note = {R package version 1.1.3},
  url = {https://CRAN.R-project.org/package=tidyr},
}
@Article{R-tidyverse,
  title = {Welcome to the {tidyverse}},
  author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
  year = {2019},
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  doi = {10.21105/joss.01686},
}
