@book{kruschke_doing_2014,
	location = {Burlington, {MA}},
	edition = {2nd Edition},
	title = {Doing Bayesian Data Analysis: A Tutorial Introduction with R},
	isbn = {978-0-12-381486-9},
	shorttitle = {Doing Bayesian Data Analysis},
	abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis, A Tutorial Introduction with R and {BUGS}, provides an accessible approach to Bayesian Data Analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. The text delivers comprehensive coverage of all scenarios addressed by non-Bayesian textbooks- t-tests, analysis of variance ({ANOVA}) and comparisons in {ANOVA}, multiple regression, and chi-square (contingency table analysis). This book is intended for first year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Prerequisite is knowledge of algebra and basic calculus. Free software now includes programs in {JAGS}, which runs on Macintosh, Linux, and Windows. Author website: http://www.indiana.edu/{\textasciitilde}kruschke/{DoingBayesianDataAnalysis}/Provides complete examples with R programming language and {BUGS} software (both Freeware)  Addresses topics such as experiment planning, power analysis and sample size planning Includes numerous exercises with explicit purposes and guidelines for accomplishment.},
	pagetotal = {673},
	publisher = {Academic Press},
	author = {Kruschke, John K.},
	date = {2014},
	langid = {english},
}

@book{gelman_bayesian_2013,
	location = {Boca Raton},
	title = {Bayesian Data Analysis, Third Edition},
	isbn = {978-1-4398-4095-5},
	abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
	pagetotal = {677},
	publisher = {Chapman and Hall/{CRC}},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	date = {2013-11-01},
	langid = {english},
	note = {00000},
}

@book{bolger_intensive_2013,
	title = {Intensive Longitudinal Methods: An Introduction to Diary and Experience Sampling Research},
	isbn = {978-1-4625-0678-1},
	url = {http://www.intensivelongitudinal.com/},
	shorttitle = {Intensive Longitudinal Methods},
	abstract = {A complete, practical guide to planning and executing an intensive longitudinal study, this book provides the tools for understanding within-subject social, psychological, and physiological processes in everyday contexts. Intensive longitudinal studies involve many repeated measurements taken on individuals, dyads, or groups, and include diary and experience sampling studies. A range of engaging, worked-through research examples with datasets are featured. Coverage includes how to: select the best intensive longitudinal design for a particular research question, model within-subject change processes for continuous and categorical outcomes, distinguish within-subject from between-subjects effects, assess the reliability of within-subject changes, assure sufficient statistical power, and more. Several end-of-chapter write-ups illustrate effective ways to present study findings for publication. Datasets and output for the examples are available for readers' use at the companion website. The website also includes {HLM}, {MLwin}, and R code as an alternative to the {SPSS}, {SAS}, and Mplus code presented in the book.},
	pagetotal = {274},
	publisher = {Guilford Press},
	author = {Bolger, Niall and Laurenceau, Jean-Philippe},
	date = {2013-02-14},
	langid = {english},
}
@software{rcoreteamLanguageEnvironmentStatistical2025,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}. {{Version}} 4.4.3},
  author = {{R Core Team}},
  date = {2025},
  location = {Vienna, Austria},
  url = {https://www.R-project.org/},
  organization = {R Foundation for Statistical Computing},
  version = {4.4.3},
  keywords = {nosource}
}
@software{standevelopmentteamStanModelingLanguage2024,
  title = {Stan {{Modeling Language Users Guide}} and {{Reference Manual}}, Version 2.36},
  author = {Stan Development Team},
  date = {2024},
  url = {https://mc-stan.org},
  version = {2.36},
  keywords = {nosource}
}
@Article{rouder_introduction_2005,
  title = {An Introduction to {{Bayesian}} Hierarchical Models with an Application in the Theory of Signal Detection},
  volume = {12},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03196750},
  timestamp = {2016-08-17T16:32:29Z},
  langid = {english},
  number = {4},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  author = {Jeffrey N. Rouder and Jun Lu},
  urldate = {2016-05-12},
  date = {2005-08},
  pages = {573--604},
  note = {00203},
}
@Article{rouder_signal_2007,
  title = {Signal {{Detection Models}} with {{Random Participant}} and {{Item Effects}}},
  volume = {72},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-005-1350-6},
  timestamp = {2017-05-19T00:33:06Z},
  langid = {english},
  number = {4},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  author = {Jeffrey N. Rouder and Jun Lu and Dongchu Sun and Paul Speckman and Richard D. Morey and Moshe Naveh-Benjamin},
  urldate = {2015-05-25},
  date = {2007-03-19},
  pages = {621--642},
  note = {00066},
}
@Article{decarlo_signal_1998,
  title = {Signal Detection Theory and Generalized Linear Models},
  volume = {3},
  rights = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  doi = {10.1037/1082-989X.3.2.186},
  timestamp = {2017-07-06T17:44:15Z},
  langid = {english},
  number = {2},
  journaltitle = {Psychological Methods},
  author = {Lawrence T. DeCarlo},
  date = {1998},
  pages = {186--205},
  note = {00167},
}
@Article{burkner_brms:_2017,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  volume = {80},
  doi = {10.18637/jss.v080.i01},
  timestamp = {2017-08-18T13:02:03Z},
  number = {1},
  journaltitle = {Journal of Statistical Software},
  author = {Paul-Christian B{\"u}rkner},
  date = {2017},
  pages = {1--28},
}
@Software{wright_sdtalt:_2011,
  title = {Sdtalt: {{Signal}} Detection Theory and Alternatives},
  url = {https://CRAN.R-project.org/package=sdtalt},
  timestamp = {2017-10-03T21:06:59Z},
  author = {Daniel B. Wright},
  date = {2011},
  note = {00000},
}

@Article{skagerberg_manipulating_2008,
  title = {Manipulating Power Can Affect Memory Conformity},
  volume = {22},
  issn = {1099-0720},
  doi = {10.1002/acp.1353},
  timestamp = {2017-10-03T21:07:23Z},
  langid = {english},
  number = {2},
  journaltitle = {Applied Cognitive Psychology},
  shortjournal = {Appl. Cognit. Psychol.},
  author = {Elin M. Skagerberg and Daniel B. Wright},
  urldate = {2017-10-03},
  date = {2008-03-01},
  pages = {207--216},
  note = {00053},
}
@Article{stanislaw_calculation_1999,
  title = {Calculation of Signal Detection Theory Measures},
  volume = {31},
  url = {http://link.springer.com/article/10.3758/BF03207704},
  timestamp = {2016-05-04T18:57:40Z},
  number = {1},
  journaltitle = {Behavior research methods, instruments, \& computers},
  author = {Harold Stanislaw and Natasha Todorov},
  urldate = {2014-12-23},
  date = {1999},
  pages = {137--149},
}
@Article{decarlo_statistical_2010,
  title = {On the Statistical and Theoretical Basis of Signal Detection Theory and Extensions: {{Unequal}} Variance, Random Coefficient, and Mixture Models},
  volume = {54},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2010.01.001},
  shorttitle = {On the Statistical and Theoretical Basis of Signal Detection Theory and Extensions},
  timestamp = {2017-10-03T21:15:20Z},
  number = {3},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  author = {Lawrence T. DeCarlo},
  urldate = {2017-09-28},
  date = {2010-06-01},
  pages = {304--313},
  note = {00032},
}
@Article{koen_examining_2013,
  title = {Examining the Causes of Memory Strength Variability: {{Recollection}}, Attention Failure, or Encoding Variability?},
  volume = {39},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/a0033671},
  timestamp = {2017-10-06T13:51:53Z},
  number = {6},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  author = {Joshua D. Koen and Mariam Aly and Wei-Chun Wang and Andrew P. Yonelinas},
  date = {2013},
  pages = {1726--1741},
}
@Article{ravenzwaaij_simple_2016,
  title = {A Simple Introduction to {{Markov Chain Monte}}–{{Carlo}} Sampling},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-016-1015-8},
  timestamp = {2016-08-17T16:33:44Z},
  langid = {english},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  author = {Don {van Ravenzwaaij} and Pete Cassey and Scott D. Brown},
  urldate = {2016-03-23},
  date = {2016-03-11},
  pages = {1--12},
  note = {00000},
}
@Book{macmillan_detection_2005,
  location = {{Mahwah, N.J}},
  edition = {2nd ed},
  title = {Detection Theory: A User's Guide},
  isbn = {0-8058-4230-6 0-8058-4231-4},
  shorttitle = {Detection Theory},
  pagetotal = {492},
  timestamp = {2016-04-11T00:36:41Z},
  publisher = {{Lawrence Erlbaum Associates}},
  author = {Neil A. Macmillan and C. Douglas Creelman},
  date = {2005},
  note = {05479},
}
@Article{decarlo_using_2003,
  title = {Using the {{PLUM}} Procedure of {{SPSS}} to Fit Unequal Variance and Generalized Signal Detection Models},
  volume = {35},
  issn = {0743-3808, 1532-5970},
  doi = {10.3758/BF03195496},
  timestamp = {2017-10-03T21:15:19Z},
  langid = {english},
  number = {1},
  journaltitle = {Behavior Research Methods, Instruments, \& Computers},
  shortjournal = {Behavior Research Methods, Instruments, \& Computers},
  author = {Lawrence T. Decarlo},
  urldate = {2017-09-28},
  date = {2003-02-01},
  pages = {49--56},
}
@Article{pratte_separating_2010,
  title = {Separating Mnemonic Process from Participant and Item Effects in the Assessment of {{ROC}} Asymmetries.},
  volume = {36},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/a0017682},
  timestamp = {2017-10-18T17:19:22Z},
  number = {1},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  author = {Michael S. Pratte and Jeffrey N. Rouder and Richard D. Morey},
  date = {2010},
  pages = {224--232},
  note = {00040},
}

@Article{morey_problematic_2008,
  title = {Problematic Effects of Aggregation in z {{ROC}} Analysis and a Hierarchical Modeling Solution},
  volume = {52},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2008.02.001},
  timestamp = {2017-10-20T18:48:30Z},
  number = {6},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  author = {Richard D. Morey and Michael S. Pratte and Jeffrey N. Rouder},
  urldate = {2017-10-20},
  date = {2008-12-01},
  pages = {376--388},
}
@Article{koen_memory_2010,
  title = {Memory Variability Is Due to the Contribution of Recollection and Familiarity, Not to Encoding Variability.},
  volume = {36},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/a0020448},
  timestamp = {2017-10-20T19:16:05Z},
  number = {6},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  author = {Joshua D. Koen and Andrew P. Yonelinas},
  date = {2010},
  pages = {1536--1542},
  note = {00039},
}
@Article{singmann_mptinr:_2013,
  title = {{{MPTinR}}: {{Analysis}} of Multinomial Processing Tree Models in {{R}}},
  volume = {45},
  doi = {10.3758/s13428-012-0259-0},
  timestamp = {2017-10-22T17:07:12Z},
  number = {2},
  journaltitle = {Behavior Research Methods},
  author = {Henrik Singmann and David Kellen},
  date = {2013},
  pages = {560--575},
  note = {00049},
}
@Article{estes_problem_1956,
  title = {The Problem of Inference from Curves Based on Group Data},
  volume = {53},
  rights = {(c) 2012 APA, all rights reserved},
  issn = {1939-1455(Electronic);0033-2909(Print)},
  doi = {10.1037/h0045156},
  timestamp = {2016-05-04T18:55:52Z},
  number = {2},
  journaltitle = {Psychological Bulletin},
  author = {W.K. Estes},
  date = {1956},
  pages = {134--140},
  note = {00495},
}
@book{greenSignalDetectionTheory1966,
  title = {Signal Detection Theory and Psychophysics},
  author = {Green, David Marvin and Swets, John A.},
  date = {1966},
  eprint = {Ykt9AAAAMAAJ},
  eprinttype = {googlebooks},
  publisher = {Wiley},
  location = {New York, NY},
  langid = {english},
  pagetotal = {484},
  keywords = {nosource,Psychology / Physiological Psychology}
}
@online{leeuwenSmokedetectorPrinciplePathogen2024,
  title = {The Smoke-Detector Principle of Pathogen Avoidance: {{A}} Test of How the Behavioral Immune System Gives Rise to Prejudice (Stage 1 Registered Report)},
  shorttitle = {The Smoke-Detector Principle of Pathogen Avoidance},
  author = {family=Leeuwen, given=Florian, prefix=van, useprefix=false and Jaeger, Bastian and Axelsson, John and Becker, David Vaughn and Hansson, Lina and Lasselin, Julie and Lekander, Mats and Tybur, Joshua M. and Vuorre, Matti},
  date = {2024-09-30},
  eprinttype = {OSF},
  doi = {10.31234/osf.io/e874s},
  url = {https://osf.io/e874s_v1},
  urldate = {2025-03-19},
  abstract = {Motivations to avoid infectious disease seem to influence prejudice toward some groups, including groups not explicitly associated with infectious disease. The standard explanation relies on signal detection theory and proposes that pathogen detection should be biased toward making many false alarms (false positives) and few misses (false negatives). Therefore, pathogen detection mechanisms arguably categorize a broad array of atypical features as indicative of infection, which gives rise to negative affect toward people with atypical features. We will test a key hypothesis derived from this explanation: specific appearance-based prejudices are associated with tendencies to make false alarms when estimating the presence of infectious disease. While this hypothesis is implicit in much work on the behavioral immune system and prejudice, direct tests of it are lacking and existing relevant work contains important limitations. We will conduct a cross-sectional study with a large US sample that includes measures of tendencies to make false alarms and prejudice toward multiple relevant social groups/categories.},
  langid = {american},
  pubstate = {prepublished},
  keywords = {disgust,face perception,infectious disease,prejudice,signal detection theory}
}
@article{zloteanuTutorialDeceptionDetection2024,
  title = {A {{Tutorial}} for {{Deception Detection Analysis}} or: {{How I Learned}} to {{Stop Aggregating Veracity Judgments}} and {{Embraced Signal Detection Theory Mixed Models}}},
  shorttitle = {A {{Tutorial}} for {{Deception Detection Analysis}} Or},
  author = {Zloteanu, Mircea and Vuorre, Matti},
  date = {2024-03-01},
  journaltitle = {Journal of Nonverbal Behavior},
  shortjournal = {J Nonverbal Behav},
  issn = {1573-3653},
  doi = {10.1007/s10919-024-00456-x},
  url = {https://doi.org/10.1007/s10919-024-00456-x},
  urldate = {2024-03-01},
  abstract = {Historically, deception detection research has relied on factorial analyses of response accuracy to make inferences. However, this practice overlooks important sources of variability resulting in potentially misleading estimates and may conflate response bias with participants' underlying sensitivity to detect lies from truths. We showcase an alternative approach using a signal detection theory (SDT) with generalized linear mixed models framework to address these limitations. This SDT approach incorporates individual differences from both judges and senders, which are a principal source of spurious findings in deception research. By avoiding data transformations and aggregations, this methodology outperforms traditional methods and provides more informative and reliable effect estimates. This well-established framework offers researchers a powerful tool for analyzing deception data and advances our understanding of veracity judgments. All code and data are openly available.},
  langid = {english},
  keywords = {Bias,Deception detection,Mixed effects models,Signal detection theory,Veracity}
}
@book{wickensElementarySignalDetection2001,
  title = {Elementary {{Signal Detection Theory}}},
  author = {Wickens, Thomas D.},
  date = {2001-10-11},
  eprint = {s3pGN_se4v0C},
  eprinttype = {googlebooks},
  publisher = {Oxford University Press},
  abstract = {Signal detection theory, as developed in electrical engineering and based on statistical decision theory, was first applied to human sensory discrimination about 40 years ago. The theory's intent was to explain how humans discriminate and how we might use reliable measures to quantify this ability. An interesting finding of this work is that decisions are involved even in the simplest of discrimination tasks--say, determining whether or not a sound has been heard (a yes-no decision). Detection theory has been applied to a host of varied problems (for example, measuring the accuracy of diagnostic systems, survey research, reliability of lie detection tests) and extends far beyond the detection of signals. This book is a primer on signal detection theory, useful for both undergraduates and graduate students.},
  isbn = {978-0-19-535780-6},
  langid = {english},
  pagetotal = {284},
  keywords = {Mathematics / Probability & Statistics / General,Psychology / Cognitive Psychology & Cognition,Signal detection theory,Technology & Engineering / Electrical}
}
@article{snodgrassPragmaticsMeasuringRecognition1988,
  title = {Pragmatics of Measuring Recognition Memory: {{Applications}} to Dementia and Amnesia.},
  shorttitle = {Pragmatics of Measuring Recognition Memory},
  author = {Snodgrass, Joan G. and Corwin, June},
  date = {1988-03-01},
  journaltitle = {Journal of Experimental Psychology: General},
  shortjournal = {Journal of Experimental Psychology: General},
  volume = {117},
  number = {1},
  pages = {34--50},
  publisher = {American Psychological Association},
  issn = {0096-3445},
  doi = {10.1037/0096-3445.117.1.34},
  url = {https://research.ebsco.com/linkprocessor/plink?id=faca2a42-34ab-33fe-a589-805ddb145e82},
  urldate = {2025-03-21},
  abstract = {This article has two purposes. The first is to describe four theoretical models of yes-no recognition memory and present their associated measures of discrimination and response bias. These models are then applied to a set of data from normal subjects to determine which pairs of discrimination and bias indices show independence between discrimination and bias. The second purpose is to use the indices from the acceptable models to characterize recognition memory deficits in dementia and amnesia. Young normal subjects, Alzheimer's disease patients, and parkinsonian dementia patients were tested with picture recognition tasks with repeated study--test trials. Huntington's disease patients, mixed etiology amnesics, and age-matched normals were tested by Butters, Wolfe, Martone, Granholm, and Cermak (1985) using the same paradigm with word stimuli. Three major points are emphasized. First, any index of recognition memory performance assumes an underlying model. Second, even acceptable models can lead to different conclusions about patterns of learning and forgetting. Third, efforts to characterize and ameliorate abnormal memory should address both discrimination and bias deficits. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  langid = {english},
  keywords = {Adulthood (18 yrs & older),Aged (65 yrs & older),Alzheimer's Disease,Experimentation,Memory,Neuropsychological Assessment,Parkinson's Disease,Recognition (Learning)}
}
@book{cetinkaya-rundelIntroductionModernStatistics2024,
  title = {Introduction to {{Modern Statistics}}},
  author = {Çetinkaya-Rundel, Mine and Hardin, Johanna},
  date = {2024},
  eprint = {kaiEzgEACAAJ},
  eprinttype = {googlebooks},
  publisher = {OpenIntro},
  url = {https://openintro-ims.netlify.app/},
  isbn = {978-1-943450-14-5},
  langid = {english},
  pagetotal = {549},
  keywords = {Mathematics / General,Science / General}
}

@book{gelmanDataAnalysisUsing2007,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  date = {2007},
  publisher = {Cambridge University Press},
  location = {New York, NY},
  url = {http://www.stat.columbia.edu/~gelman/arm/},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout. Author resource page: http://www.stat.columbia.edu/\textasciitilde gelman/arm/},
  isbn = {978-0-521-68689-1},
  langid = {english},
  pagetotal = {654},
  keywords = {_tablet,Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Regression Analysis,Political Science / General,Psychology / Assessment Testing & Measurement,Statistics},
  annotation = {00058}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical Rethinking},
  author = {McElreath, Richard},
  date = {2020},
  series = {{{CRC}} Texts in Statistical Science},
  edition = {2},
  publisher = {{Taylor and Francis, CRC Press}},
  location = {Boca Raton},
  url = {https://xcelab.net/rm/statistical-rethinking/},
  abstract = {"Statistical Rethinking: A Bayesian Course with Examples in R and Stan, Second Edition builds knowledge/confidence in statistical modeling. Pushes readers to perform step-by-step calculations (usually automated.) Unique, computational approach ensures readers understand details to make reasonable choices and interpretations in their modeling work"--},
  isbn = {978-0-367-13991-9},
  langid = {english},
  keywords = {_tablet}
}
@article{kruschkeBayesianDataAnalysis2017,
  title = {Bayesian Data Analysis for Newcomers},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  date = {2017-04-12},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  pages = {1--23},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1272-1},
  url = {https://link.springer.com/article/10.3758/s13423-017-1272-1},
  urldate = {2017-04-13},
  abstract = {This article explains the foundational concepts of Bayesian data analysis using virtually no mathematical notation. Bayesian ideas already match your intuitions from everyday reasoning and from traditional data analysis. Simple examples of Bayesian data analysis are presented that illustrate how the information delivered by a Bayesian analysis can be directly interpreted. Bayesian approaches to null-value assessment are discussed. The article clarifies misconceptions about Bayesian methods that newcomers might have acquired elsewhere. We discuss prior distributions and explain how they are not a liability but an important asset. We discuss the relation of Bayesian data analysis to Bayesian models of mind, and we briefly discuss what methodological problems Bayesian data analysis is not meant to solve. After you have read this article, you should have a clear sense of how Bayesian data analysis works and the sort of information it delivers, and why that information is so intuitive and useful for drawing conclusions from data.},
  langid = {english},
  keywords = {Statistics},
  annotation = {00000}
}

@article{kruschkeBayesianNewStatistics2017,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  date = {2017-02-07},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  pages = {1--29},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  url = {https://link.springer.com/article/10.3758/s13423-016-1221-4},
  urldate = {2017-07-05},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  langid = {english},
  keywords = {Statistics},
  annotation = {00000}
}
@book{gelmanRegressionOtherStories2020,
  title = {Regression and {{Other Stories}}},
  author = {Gelman, Andrew and Hill, Jennifer and Vehtari, Aki},
  date = {2020},
  publisher = {Cambridge University Press},
  url = {https://avehtari.github.io/ROS-Examples/},
  langid = {english},
  keywords = {_tablet}
}
@incollection{lickliderThreeAuditoryTheories1959,
  title = {Three Auditory Theories},
  booktitle = {Psychology: {{A Study Of A Science Volume}}},
  author = {Licklider, J. C. R},
  editor = {Koch, Sigmund},
  date = {1959},
  volume = {1: Sensory Perceptual And Physiological Formulations},
  publisher = {McGraw-Hill},
  url = {https://archive.org/details/in.ernet.dli.2015.74438}
}
@online{vuorreCommunicatingCausalEffect2024,
  title = {Communicating Causal Effect Heterogeneity},
  author = {Vuorre, Matti and Kay, Matthew and Bolger, Niall},
  date = {2024-09-03},
  eprinttype = {OSF},
  doi = {10.31234/osf.io/mwg4f},
  url = {https://osf.io/mwg4f},
  urldate = {2024-09-09},
  abstract = {Advances in experimental, data collection, and analysis methods have brought population variability in psychological phenomena to the fore. Yet, current practices for interpreting such heterogeneity do not appropriately treat the uncertainty inevitable in any statistical summary. Heterogeneity is best thought of as a distribution of features with a mean (average person's effect) and variance (between-person differences). This expected heterogeneity distribution can be further summarized e.g. as a heterogeneity interval (Bolger et al., 2019). However, because empirical studies estimate the underlying mean and variance parameters with uncertainty, the expected distribution and interval will underestimate the actual range of plausible effects in the population. Using Bayesian hierarchical models, and with the aid of empirical datasets from social and cognitive psychology, we provide a walk-through of effective heterogeneity reporting and display tools that appropriately convey measures of uncertainty. We cover interval, proportion, and ratio measures of heterogeneity and their estimation and interpretation. These tools can be a spur to theory building, allowing researchers to widen their focus from population averages to population heterogeneity in psychological phenomena.},
  langid = {american},
  pubstate = {prepublished},
  keywords = {heterogeneity,multilevel model,statistics,uncertainty,variation,visualization},
  annotation = {data: https://github.com/mvuorre/heterogeneity-uncertainty}
}
@article{efronSteinsParadoxStatistics1977,
  title = {Stein's {{Paradox}} in {{Statistics}}},
  author = {Efron, Bradley and Morris, Carl},
  date = {1977},
  journaltitle = {Scientific American},
  volume = {236},
  number = {5},
  eprint = {24954030},
  eprinttype = {jstor},
  pages = {119--127},
  publisher = {Scientific American, a division of Nature America, Inc.},
  issn = {0036-8733},
  url = {https://www.jstor.org/stable/24954030},
  urldate = {2023-06-03}
}
@article{liddellAnalyzingOrdinalData2018,
  title = {Analyzing Ordinal Data with Metric Models: {{What}} Could Possibly Go Wrong?},
  shorttitle = {Analyzing Ordinal Data with Metric Models},
  author = {Liddell, Torrin M. and Kruschke, John K.},
  date = {2018-11-01},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {79},
  pages = {328--348},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2018.08.009},
  url = {http://www.sciencedirect.com/science/article/pii/S0022103117307746},
  urldate = {2018-10-15},
  abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term ``Likert,'' and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems --- false alarms, misses, and inversions --- for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
  keywords = {Bayesian analysis,Likert,Ordered-probit,Ordinal data}
}
@article{burknerOrdinalRegressionModels2019,
  title = {Ordinal {{Regression Models}} in {{Psychology}}: {{A Tutorial}}},
  shorttitle = {Ordinal {{Regression Models}} in {{Psychology}}},
  author = {B\"urkner, Paul-Christian and Vuorre, Matti},
  date = {2019-03-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {1},
  pages = {77--101},
  issn = {2515-2459},
  doi = {10.1177/2515245918823199},
  url = {https://doi.org/10.1177/2515245918823199},
  urldate = {2019-12-02},
  abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
  langid = {english},
  keywords = {brms,Likert items,open data,open materials,ordinal models,R},
  annotation = {data: https://osf.io/cu8jv/\\
preprint: https://doi.org/10.31234/osf.io/x8swp}
}
@article{burknerBayesianItemResponse2021,
  title = {Bayesian {{Item Response Modeling}} in {{R}} with Brms and {{Stan}}},
  author = {B\"urkner, Paul-Christian},
  date = {2021-11-30},
  journaltitle = {Journal of Statistical Software},
  volume = {100},
  pages = {1--54},
  issn = {1548-7660},
  doi = {10.18637/jss.v100.i05},
  url = {https://doi.org/10.18637/jss.v100.i05},
  urldate = {2025-03-31},
  abstract = {Item response theory (IRT) is widely applied in the human sciences to model persons' responses on a set of items measuring one or more latent constructs. While several R packages have been developed that implement IRT models, they tend to be restricted to respective pre-specified classes of models. Further, most implementations are frequentist while the availability of Bayesian methods remains comparably limited. I demonstrate how to use the R package brms together with the probabilistic programming language Stan to specify and fit a wide range of Bayesian IRT models using flexible and intuitive multilevel formula syntax. Further, item and person parameters can be related in both a linear or non-linear manner. Various distributions for categorical, ordinal, and continuous responses are supported. Users may even define their own custom response distribution for use in the presented framework. Common IRT model classes that can be specified natively in the presented framework include 1PL and 2PL logistic models optionally also containing guessing parameters, graded response and partial credit ordinal models, as well as drift diffusion models of response times coupled with binary decisions. Posterior distributions of item and person parameters can be conveniently extracted and postprocessed. Model fit can be evaluated and compared using Bayes factors and efficient cross-validation procedures.},
  langid = {english},
  keywords = {Bayesian Statistics,brms,Item Response Theory,R,Stan}
}
  @Manual{tidybayes2024,
    title = {{tidybayes}: Tidy Data and Geoms for {Bayesian} Models},
    author = {Matthew Kay},
    year = {2024},
    note = {R package version 3.0.7},
    url = {http://mjskay.github.io/tidybayes/},
    doi = {10.5281/zenodo.1308151},
  }
@article{kellenTestingFoundationsSignal2021,
  title = {Testing the Foundations of Signal Detection Theory in Recognition Memory.},
  author = {Kellen, David and Winiger, Samuel and Dunn, John C. and Singmann, Henrik},
  date = {2021-11-01},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {128},
  number = {6},
  pages = {1022--1050},
  publisher = {American Psychological Association},
  issn = {0033-295X},
  doi = {10.1037/rev0000288},
  url = {https://research.ebsco.com/linkprocessor/plink?id=b618ce70-0d1e-3f1b-a120-5d0c6a30b902},
  urldate = {2025-04-04},
  abstract = {Signal detection theory (SDT) plays a central role in the characterization of human judgments in a wide range of domains, most prominently in recognition memory. But despite its success, many of its fundamental properties are often misunderstood, especially when it comes to its testability. The present work examines five main properties that are characteristic of existing SDT models of recognition memory: (a) random-scale representation, (b) latent-variable independence, (c) likelihood-ratio monotonicity, (d) ROC function asymmetry, and (e) nonthreshold representation. In each case, we establish testable consequences and test them against data collected in the appropriately designed recognition-memory experiment. We also discuss the connection between yes--no, forced-choice, and ranking judgments. This connection introduces additional behavioral constraints and yields an alternative method of reconstructing yes--no ROC functions. Overall, the reported results provide a strong empirical foundation for SDT modeling in recognition memory. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  langid = {english},
  keywords = {Judgment,Memory,Recognition (Learning),Signal Detection (Perception),Simulation,Theories}
}
@article{leeBayesSDTSoftwareBayesian2008,
  title = {{{BayesSDT}}: {{Software}} for {{Bayesian}} Inference with Signal Detection Theory},
  shorttitle = {{{BayesSDT}}},
  author = {Lee, Michael D.},
  date = {2008-05},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behavior Research Methods},
  volume = {40},
  number = {2},
  pages = {450--456},
  issn = {1554-351X, 1554-3528},
  doi = {10.3758/BRM.40.2.450},
  url = {http://link.springer.com/10.3758/BRM.40.2.450},
  urldate = {2025-04-04},
  langid = {english}
}

@article{paulewiczBhsdtrPackageGeneralpurpose2020,
  title = {The Bhsdtr Package: A General-Purpose Method of {{Bayesian}} Inference for Signal Detection Theory Models},
  shorttitle = {The Bhsdtr Package},
  author = {Paulewicz, Borys\l aw and Blaut, Agata},
  date = {2020-10-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {52},
  number = {5},
  pages = {2122--2141},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01370-y},
  url = {https://doi.org/10.3758/s13428-020-01370-y},
  urldate = {2025-04-04},
  abstract = {We describe a novel method of Bayesian inference for hierarchical or non-hierarchical equal variance normal signal detection theory models with one or more criteria. The method is implemented as an open-source R package that uses the state-of-the-art Stan platform for sampling from posterior distributions. Our method can accommodate binary responses as well as additional ratings and an arbitrary number of nested or crossed random grouping factors. The SDT parameters can be regressed on additional predictors within the same model via intermediate unconstrained parameters, and the model can be extended by using automatically generated human-readable Stan code as a template. In the paper, we explain how our method improves on other similar available methods, give an overview of the package, demonstrate its use by providing a real-study data analysis walk-through, and show that the model successfully recovers known parameter values when fitted to simulated data. We also demonstrate that ignoring a hierarchical data structure may lead to severely biased estimates when fitting signal detection theory models.},
  langid = {english},
  keywords = {Bayesian inference,Hierarchical models,Signal detection theory}
}
@article{cohenSdtluPackageSignal2021,
  title = {Sdtlu: {{An R}} Package for the Signal Detection Analysis of Eyewitness Lineup Data},
  shorttitle = {Sdtlu},
  author = {Cohen, Andrew L. and Starns, Jeffrey J. and Rotello, Caren M.},
  date = {2021-02-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {53},
  number = {1},
  pages = {278--300},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01402-7},
  url = {https://doi.org/10.3758/s13428-020-01402-7},
  urldate = {2025-04-04},
  abstract = {In a standard eyewitness lineup scenario, a witness observes a culprit commit a crime and is later asked to identify the culprit from a set of faces, the lineup. Signal detection theory (SDT), a powerful modeling framework for analyzing data, has recently become a common way to analyze lineup data. The goal of this paper is to introduce a new R package, sdtlu (Signal Detection Theory -- LineUp), that streamlines and automates the SDT analysis of lineup data. sdtlu provides functions to process lineup data, determine the best-fitting SDT parameters, compute model-based performance measures such as area under the curve (AUC) and diagnosticity, use bootstrapping to determine uncertainty intervals around these parameters and measures, and compare parameters across two different data sets. The package incorporates closed-form solutions for both simultaneous and sequential lineups that allow for model-based analyses without Monte Carlo simulation. Show-ups are also supported. The package can estimate the base-rate of lineups that include a guilty suspect when the guilt or innocence of each suspect in the data set is unknown, as in ``real-world'' lineups. The package can also produce a full set of graphs, including data and model-based ROC curves and the underlying SDT model.},
  langid = {english},
  keywords = {Computational modeling,Eyewitness lineups,R package,Signal detection}
}
