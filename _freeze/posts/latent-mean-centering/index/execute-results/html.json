{
  "hash": "b685eec048c358ee8e8b5dace3de5891",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Latent mean centering with brms\ndescription: 'Researchers studying longitudinal data routinely center their predictors to isolate between- and within-cluster contrasts [@endersCenteringPredictorVariables2007]. This within-cluster centering is usually an easy data-manipulation step. However, centering variables on the observed means can bias the resulting estimates, a problem that is avoided with latent mean centering, and that is available only in the commercial MPlus software suite (and Stan!). In this entry, I show how to latent-mean-center variables in multilevel models using brms.'\ndate: 2023-01-01\ndate-modified: now\ncategories:\n  - R\n  - modelling\n  - bayes\n  - centering\n  - longitudinal\n  - brms\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Code\"\n    code-overflow: wrap\n    from: markdown+emoji\nimage: \"index_files/figure-html/fig-data-1.png\"\ndraft: false\nbibliography: references.bib\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Packages\nlibrary(knitr)\nlibrary(brms)\nlibrary(ggthemes)\nlibrary(scales)\nlibrary(posterior)\nlibrary(tidyverse)\n\n# Plotting theme\ntheme_set(\n  theme_few() +\n  theme(\n    axis.title.y = element_blank(),\n    legend.title = element_blank(), \n    panel.grid.major = element_line(linetype = \"dotted\", linewidth = .1),\n    legend.position = \"bottom\", \n    legend.justification = \"left\"\n  )\n)\n\n# Download and uncompress McNeish and Hamaker materials if not yet done\ndir.create(\"cache\")\npath <- \"materials/materials.zip\"\nif (!file.exists(path)) {\n  dir.create(\"materials\", showWarnings = FALSE)\n  download.file(\n    \"https://files.osf.io/v1/resources/wuprx/providers/osfstorage/5bfc839601593f0016774697/?zip=\",\n    destfile = path\n  )\n  unzip(path, exdir = \"materials\")\n}\n```\n:::\n\n\n## Introduction\n\nWithin-cluster centering, or *person-mean centering* (psychologists' clusters are typically persons), is an easy data processing step that allows separating within-person from between-person associations. For example, consider the example data of 100 people's ratings of urge to smoke and depression, collected over 50 days with one response per day [@mcneishPrimerTwolevelDynamic2020] [^1], shown in @tbl-data and @fig-data.\n\n[^1]: Grab a free copy at <https://osf.io/j56bm/download>. I couldn't figure if this example data is real or simulated, or what the measurement instruments were.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- read_csv(\n  \"materials/Data/Two-Level Data.csv\", \n  col_names = c(\"urge\", \"dep\", \"js\", \"hs\", \"person\", \"time\")\n) |> \n  select(-hs, -js) |> \n  relocate(person, time, 1) |> \n  mutate(\n    person = factor(person),\n    time = as.integer(time)\n  ) |> \n  mutate(\n    u_lag = lag(urge),\n    dep_lag = lag(dep),\n    .by = person\n  )\n```\n:::\n\n::: {#tbl-data .cell tbl-cap='Example longitudinal data (McNeish & Hamaker, 2020); first three rows from two random participants.'}\n::: {.cell-output-display}\n\n\n|person | time|  urge|   dep| u_lag| dep_lag|\n|:------|----:|-----:|-----:|-----:|-------:|\n|1      |    1|  0.34|  0.43|    NA|      NA|\n|1      |    2| -0.48| -0.68|  0.34|    0.43|\n|1      |    3| -4.44| -1.49| -0.48|   -0.68|\n|2      |    1|  1.65|  0.68|    NA|      NA|\n|2      |    2|  0.31|  1.49|  1.65|    0.68|\n|2      |    3|  0.46|  0.03|  0.31|    1.49|\n\n\n:::\n:::\n\n\n@tbl-data shows the original data values. Those could then be transformed to person-means and person-mean centered deviations with simple data processing. However, the person-mean is an unknown quantity, and centering on the observed value rather than an estimate of the true \"latent\" quantity can be problematic. Specifically, observed mean centering leads to Nickell's (negative bias in autoregressive effects) and LÃ¼dtke's (bias in other time-varying effects) biases [@mcneishPrimerTwolevelDynamic2020, p. 617-618].\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(999)\npids <- factor(sample(1:100, 4))\n\ndat |> \n  filter(person %in% pids) |> \n  pivot_longer(c(urge, dep)) |> \n  rename(Time = time) |> \n  mutate(name = factor(name, labels = c(\"Depression\", \"Urge\"))) |> \n  ggplot(aes(Time, value, col = name)) +\n  geom_line(linewidth = .5) +\n  facet_wrap(\"person\", nrow = 1, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![Four persons' depression and urge to smoke over time](index_files/figure-html/fig-data-1.png){#fig-data width=672}\n:::\n:::\n\n\nSo, what to do? McNeish and Hamaker [-@mcneishPrimerTwolevelDynamic2020] and others discuss latent mean centering, which accounts for uncertainty in the person-means appropriately, and thus debiases the estimated coefficients. Latent mean centering is done inside the model, and means treating the means as estimated parameters. However, I have only been able to find examples that do this latent mean centering in MPlus [@mcneishPrimerTwolevelDynamic2020] and Stan (<https://experienced-sampler.netlify.app/post/stan-hierarchical-ar/>). My goal here is to show how latent mean centering can be done in the [Stan](https://mc-stan.org) front-end R package [brms](https://paul-buerkner.github.io/brms/).\n\n## Univariate latent means model\n\nWe begin with a univariate model of the urge to smoke. This model examines the degree of autocorrelation in the urge to smoke and how it varies between people. For individual *i* in 1...I=100 and time point *t* in 1...T=50, we model `urge` (U) as normally distributed. We model the mean on person-specific intercepts $\\alpha_i$ and slopes $\\phi_i$ of that person's within-person centered `urge` at a previous time point ($U^c_{it-1}$). I model person-specific deviations as multivariate normal but do not model correlations between the intercepts and slopes for consistency with [@mcneishPrimerTwolevelDynamic2020].\n\n$$\n\\begin{align}\nU_{it} &\\sim N(\\alpha_i + \\phi_i U^c_{it-1}, \\sigma^2), \\\\\nU^{c}_{it-1} &= U^{\\text{raw}}_{it-1} - \\alpha_i, \\\\\n\\alpha_i &= \\gamma_{0} + u_{0i}, \\\\\n\\phi_i &= \\gamma_{1} + u_{1i}, \\\\\n\\begin{bmatrix}\n  u_{0i} \\\\ u_{1i}\n\\end{bmatrix} &\\sim MVN\\left(\n  \\begin{bmatrix}\n    0 \\\\ 0\n  \\end{bmatrix},\n  \\begin{pmatrix}\n  \\tau_\\alpha \\ & \\\\ 0 \\ &\\tau_\\phi\n  \\end{pmatrix}\n\\right).\n\\end{align}\n$$ {#eq-1}\n\nLet us pay some attention to the issue of within-person centering in @eq-1. Instead of decomposing urge to smoke into its within- and between-person components before fitting the model, we use \"latent mean centering\". What this means is that we estimate the person means ($\\alpha$) along with other model parameters, and subtract those means from the observed values (line 2 in above). I refer to the latent person-mean centered lagged urge to smoke as $U^c_{it-1}$. \n\nI use the R package brms to estimate this model. The following code chunk shows how to specify this model inside brms' `bf()` (\"brmsformula\") function. In the first line, we specify a regression equation for `urge`. Everything on the right-hand side of this formula (to the right of the tilde) is treated as a regression coefficient to be estimated from data unless it is the exact name of a variable in the data. Thus we will be estimating an `alpha` (intercept) and a `phi` (the autoregressive coefficient). \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nmodel <- bf(\n  urge ~ alpha + phi * (u_lag - alpha),\n  alpha + phi ~ 1 + (1 | person),\n  nl = TRUE\n)\n```\n:::\n\n\nOne unusual part in this syntax is `(u_lag - alpha)`. It just subtracts `alpha` from each lagged urge value in creating the predictor for `phi`. That is \"latent mean centering\". This first line can be considered the \"level 1\" equation or rather the *nonlinear* part of the model.\n\nThe second line then specifies the \"level 2\" equation, or the linear equations to predict the parameters in the above (potentially) nonlinear level 1 model. Both regression parameters are modelled on a population level average (the gamma in @eq-1) and person-specific deviations from it.\n\nThe fourth line specifying `nl = TRUE` is critical, because it allows us to specifically name parameters inside `bf()`, and thereby to e.g. construct the latent mean centered variable on the first row. We could also indicate the distribution that we assume for the data. But in this work we model everything as gaussian, which is the software default and thus doesn't need to be separately indicated. We then sample from the model. Everything from here on is standard operating procedure.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nfit <- brm(\n  model,\n  data = dat,\n  file = \"cache/brm-example-univariate\"\n)\n```\n:::\n\n\nThe object `fit` now contains the estimated model (the data, posterior samples, and lots of brms-specific information). We can call `summary(fit)` to see a default summary of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: urge ~ alpha + phi * (u_lag - alpha) \n         alpha ~ 1 + (1 | person)\n         phi ~ 1 + (1 | person)\n   Data: dat (Number of observations: 4900) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~person (Number of levels: 100) \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(alpha_Intercept)     0.78      0.07     0.67     0.92 1.00      906     1707\nsd(phi_Intercept)       0.15      0.02     0.11     0.19 1.00     2354     2767\n\nRegression Coefficients:\n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nalpha_Intercept    -0.01      0.08    -0.18     0.15 1.00      714     1207\nphi_Intercept       0.20      0.02     0.16     0.25 1.00     2424     2654\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.57      0.02     1.54     1.60 1.00     6653     2873\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nThe first few rows above print information about the model (the formulas, data, and number of posterior samples). Then, \"Multilevel Hyperparameters\" are standard deviations (and correlations, if estimated) of the parameters that we allowed to vary across individuals (as indicated by `~person`). For each of those parameters, one row indicates its posterior summary statistics; \"Estimate\" is the posterior mean, \"Est.Error\" is the posterior standard deviation, \"l-\" and \"u-95% CI\" are the lower and upper bounds of the 95% credibility interval (so the 2.5 and 97.5 percentiles of the posterior samples). Then, Rhat is the convergence metric which should be smaller than 1.05 (optimally 1.00) to indicate that the estimation algorithm has converged. \"Bulk_\" and \"Tail_ESS\" indicate the effective sample sizes of the posterior draws, and should be pretty large.\n\nThe \"Regression Coefficients\" indicate the same information but for the means of the person-specific parameters' distributions; or the \"fixed effects\". For the average person, there is a positive autocorrelation in these data. Finally, the \"Further Distributional Parameters\" indicate parameters that are specific to the outcome distribution. We used the default gaussian distribution, and thus get an estimated residual standard deviation.\n\nGoing forward we will create a small function to print out model summaries. It will take samples of the population level, group-level, and family-specific parameters, and return their 50th (median), 2.5th, and 97.5th quantiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsm <- function(x) {\n  x |> \n    as_draws_df(variable = c(\"b_\", \"sd_\", \"sigma\"), regex = TRUE) |> \n    summarise_draws(\n      ~quantile2(.x, c(.5, .025, .975))\n    ) |> \n    mutate(variable = str_remove_all(variable, \"_Intercept\"))\n}\n```\n:::\n\n\nWe show the results in @tbl-model-1.\n\n\n::: {#tbl-model-1 .cell tbl-cap='Summaries of main parameters from the example univariate model.'}\n\n```{.r .cell-code}\nfit |> \n  sm() |> \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|variable         |   q50|  q2.5| q97.5|\n|:----------------|-----:|-----:|-----:|\n|b_alpha          | -0.01| -0.18|  0.15|\n|b_phi            |  0.21|  0.16|  0.25|\n|sd_person__alpha |  0.78|  0.67|  0.92|\n|sd_person__phi   |  0.15|  0.11|  0.19|\n|sigma            |  1.57|  1.54|  1.60|\n\n\n:::\n:::\n\n\n## Multilevel AR(1) Model\n\nWe then replicate the two-level AR(1) model in @mcneishPrimerTwolevelDynamic2020 (equations 4a-c) that predicts urge from a time-lagged urge and depression. The model is\n\n$$\n\\begin{align}\nU_{it} &\\sim N(\\alpha_i + \\phi_i U^c_{it-1} + \\beta_i D^c_{it}, \\sigma^2), \\\\\nU^{c}_{it} &= U^{\\text{raw}}_{it} - \\alpha^U_i, \\\\\nD^{c}_{it} &= D^{\\text{raw}}_{it} - \\alpha^D_i, \\\\\n\\alpha^U_i &= \\gamma_{0} + u_{0i}, \\\\\n\\alpha^D_i &= \\gamma_{1} + u_{1i}, \\\\\n\\phi_i &= \\gamma_{2} + u_{2i}, \\\\\n\\beta_i &= \\gamma_{3} + u_{3i}, \\\\\n\\begin{bmatrix}\n  u_{0i} \\\\ u_{1i} \\\\ u_{2i} \\\\ u_{3i}\n\\end{bmatrix} &\\sim MVN\\left(\n  \\begin{bmatrix}\n    0 \\\\ 0 \\\\ 0 \\\\ 0\n  \\end{bmatrix},\n  \\begin{pmatrix}\n    \\tau_{\\alpha^U} \\ & \\ & & \\\\ \n    0 \\ &\\tau_{\\alpha^D} \\ & \\ & \\\\ \n    0 \\ &0 \\ &\\tau_\\phi \\ & \\\\\n    0 \\ &0 \\ &0 \\ &\\tau_\\beta\n  \\end{pmatrix}\n\\right)\n\\end{align}\n$$ {#eq-2}\n\nWe then see from @eq-2 that we need to refer to different outcomes' parameters across model formulas. That is, when predicting the urge to smoke, we need a way to refer to the (latent) mean of depression so that we can appropriately center the depression predictor. Currently brms does not support sharing parameters across formulas for different outcomes, but we can overcome this limitation with a small data wrangling trick\n\nThat is, we \"stack\" our data into the long format with respect to the two different outcomes, urge to smoke and depression. Then, on each row we have all variables from that measurement occasion, in addition to new ones that indicate the value of the outcome, and which outcome it refers to (@tbl-data-2).\n\n\n::: {#tbl-data-2 .cell tbl-cap='Rearranged data for multivariate models.'}\n\n```{.r .cell-code}\ndat <- dat |> \n  pivot_longer(c(urge, dep), names_to = \"outcome\", values_to = \"y\") |> \n  mutate(\n    i_urge = if_else(outcome == \"urge\", 1, 0),\n    i_dep = if_else(outcome == \"dep\", 1, 0)\n  ) |> \n  # Include predictors from each row\n  left_join(dat)\n\ndat |> \n  head() |> \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|person | time| u_lag| dep_lag|outcome |     y| i_urge| i_dep|  urge|   dep|\n|:------|----:|-----:|-------:|:-------|-----:|------:|-----:|-----:|-----:|\n|1      |    1|    NA|      NA|urge    |  0.34|      1|     0|  0.34|  0.43|\n|1      |    1|    NA|      NA|dep     |  0.43|      0|     1|  0.34|  0.43|\n|1      |    2|  0.34|    0.43|urge    | -0.48|      1|     0| -0.48| -0.68|\n|1      |    2|  0.34|    0.43|dep     | -0.68|      0|     1| -0.48| -0.68|\n|1      |    3| -0.48|   -0.68|urge    | -4.44|      1|     0| -4.44| -1.49|\n|1      |    3| -0.48|   -0.68|dep     | -1.49|      0|     1| -4.44| -1.49|\n\n\n:::\n:::\n\n\nGiven these data, we then reparameterize @eq-2 to also model depression in an otherwise identical model (@eq-3).\n\n$$\n\\begin{align}\nY_{it} &\\sim N(\\mu, \\sigma^2) \\\\\n\\mu &= I_{\\text{urge}}(\\alpha_{1i} + \\phi_i U^c_{it-1} + \\beta_i D^c_{it}) + I_{\\text{dep}}\\alpha_{2i} \\\\\n\\sigma &= \\text{exp}(I_{\\text{urge}}\\sigma_1 + I_{\\text{dep}}\\sigma_2) \\\\\nU^{c}_{it} &= U^{\\text{raw}}_{it} - \\alpha_{1i}, \\\\\nD^{c}_{it} &= D^{\\text{raw}}_{it} - \\alpha_{2i}, \\\\\n\\alpha_{1i} &= \\gamma_{0} + u_{0i}, \\\\\n\\alpha_{2i} &= \\gamma_{1} + u_{1i}, \\\\\n\\phi_i &= \\gamma_{2} + u_{2i}, \\\\\n\\beta_i &= \\gamma_{3} + u_{3i}, \\\\\n\\begin{bmatrix}\n  u_{0i} \\\\ u_{1i} \\\\ u_{2i} \\\\ u_{3i}\n\\end{bmatrix} &\\sim MVN\\left(\n  \\begin{bmatrix}\n    0 \\\\ 0 \\\\ 0 \\\\ 0\n  \\end{bmatrix},\n  \\begin{pmatrix}\n    \\tau_{\\alpha1} \\ & \\ & & \\\\ \n    0 \\ &\\tau_{\\alpha2} \\ & \\ & \\\\ \n    0 \\ &0 \\ &\\tau_\\phi \\ & \\\\\n    0 \\ &0 \\ &0 \\ &\\tau_\\beta\n  \\end{pmatrix}\n\\right)\n\\end{align}\n$$ {#eq-3}\n\nThat is, I model `y` that is either `urge` or `dep` as indicated by `i_urge` and `i_dep` respectively. So, below `alpha1`, `phi`, and `beta` to apply to `urge`, but `alpha2` to `dep`. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nbform <- bf(\n  y ~ \n    i_urge * (alpha1 + phi * (u_lag - alpha1) + beta * (dep - alpha2)) + \n    i_dep * alpha2,\n  nlf(sigma ~ i_urge * sigma1 + i_dep * sigma2),\n  alpha1 + phi + beta + alpha2 ~ 1 + (1 | person),\n  sigma1 + sigma2 ~ 1,\n  nl = TRUE\n)\n```\n:::\n\n\nNotice that essentially there are two models of `y` depending on the values of `i_urge` and `i_dep`. Critically, this also needs to extend to different models of the residual standard deviations. That is accomplished inside `nlf()`, where I model `sigma` on the two indicators. By default, sigmas are modelled through the log-link function, and notice that I only include a global intercept for each `sigma1` and `sigma2`; that is they are not further modelled on covariates. This is not pretty, but as we will see it works.\n\nI then sample from the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- brm(\n  bform,\n  data = dat,\n  control = list(adapt_delta = 0.95),\n  file = \"cache/brm-example-4\"\n)\n```\n:::\n\n\nAnd then compare the model summary to @mcneishPrimerTwolevelDynamic2020. We can see the estimates match to within differences in priors and MCSE (@tbl-ml). Note in the code below I transform standard deviations by first exponentiating draws of residual standard deviations, and then square to put them on the variance scale as in @mcneishPrimerTwolevelDynamic2020.\n\n\n::: {#tbl-ml .cell tbl-cap='Multilevel AR(1) model results.'}\n\n```{.r .cell-code}\nas_draws_df(fit, variable = c(\"b_\", \"sd_\"), regex = TRUE) |> \n  mutate(\n    across(starts_with(\"sd_\"), ~.^2),\n    across(starts_with(\"b_sigma\"), ~exp(.)^2)\n  ) |> \n  summarise_draws(\n    brms = ~quantile2(., probs = c(.5, .025, .975)) |> \n      number(.01) |> \n      str_glue_data(\"{q50} [{q2.5}, {q97.5}]\")\n  ) |> \n  mutate(\n    variable = str_replace(variable, \"sd_person__\", \"var_\") |> \n      str_remove_all(\"_Intercept\"),\n    `M&H (2020)` = c(\n      \"-0.01 [-0.18, 0.16]\",\n      \" 0.21 [0.17, 0.24]\",\n      \" 0.80 [0.61, 0.95]\",\n      \" 0.01 [-0.02, 0.04]\",\n      \" 1.14 [1.09, 1.19]\",\n      \"\",\n      \" 0.60 [0.44, 0.83]\",\n      \" 0.02 [0.01, 0.03]\",\n      \" 0.79 [0.61, 0.95]\",\n      \" 0.01 [0.00, 0.01]\"\n    )\n  ) |> \n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|variable   |brms                |M&H (2020)          |\n|:----------|:-------------------|:-------------------|\n|b_alpha1   |-0.01 [-0.16, 0.16] |-0.01 [-0.18, 0.16] |\n|b_phi      |0.21 [0.18, 0.25]   |0.21 [0.17, 0.24]   |\n|b_beta     |0.79 [0.62, 0.96]   |0.80 [0.61, 0.95]   |\n|b_alpha2   |0.00 [-0.02, 0.03]  |0.01 [-0.02, 0.04]  |\n|b_sigma1   |1.14 [1.10, 1.19]   |1.14 [1.09, 1.19]   |\n|b_sigma2   |1.00 [0.96, 1.04]   |                    |\n|var_alpha1 |0.59 [0.44, 0.81]   |0.60 [0.44, 0.83]   |\n|var_phi    |0.02 [0.01, 0.03]   |0.02 [0.01, 0.03]   |\n|var_beta   |0.77 [0.59, 1.03]   |0.79 [0.61, 0.95]   |\n|var_alpha2 |0.00 [0.00, 0.01]   |0.01 [0.00, 0.01]   |\n\n\n:::\n:::\n\n\n# Conclusion\n\nBecause it is easy to specify latent means in brms, I think I will be using them much more often from now on, especially if my sample size per person is small. I don't think this will make much of a difference after that sample size is greater than, say, the magic number 30.\n\nLet me know if you have any comments!\n\n# History {.appendix}\n\n:::{.callout-note}\nEarlier versions of this post contained syntax errors. The data stacking trick was suggested to me by Mauricio Garnier-Villarreal (thanks!)\n\nWhile drafting this entry, I asked for help with coding this up in brms on the Stan forums: <https://discourse.mc-stan.org/t/latent-mean-centering-latent-covariate-models-in-brms/29424>. I couldn't have figured it out without the help of all those people who answered. Thanks!\n\nThe earlier drafts and mistakes I made in coding the brms model up can be found in the [Git history](https://github.com/mvuorre/mvuorre.github.io/commits/main/posts/stan-latent-mean-centering/index.qmd) of this file :smile:\n:::\n\n# See also {.appendix}\n\nI've found these prior discussions useful\n\n-   <https://quantscience.rbind.io/2020/02/04/bayesian-mlm-with-group-mean-centering/#group-mean-centering-treating-group-means-as-latent-variables>\n-   <https://discourse.mc-stan.org/t/treat-the-cluster-mean-of-a-predictor-variable-as-a-latent-variable-hierarchical-linear-models/15001/5>\n-   <https://discourse.mc-stan.org/t/modeling-latent-means-in-brms-for-multilevel-group-mean-centering/12642/3>\n-   <https://scottclaessens.github.io/blog/2020/brmsLV/>\n-   <https://discourse.mc-stan.org/t/mi-with-non-linear-model/11227>\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}