{
  "hash": "d7028724a7e6f6b5e14780812d5a2688",
  "result": {
    "markdown": "---\ntitle: Bayesian Meta-Analysis with R, Stan, and brms\ndescription: Meta-analysis is a special case of Bayesian multilevel modeling\ndate: 2016-09-29\ncategories:\n  - statistics\n  - R\n  - brms\n  - tutorial\nimage: \"index_files/figure-html/unnamed-chunk-2-1.png\"\nbibliography: bibliography.bib\n---\n\n\n\n\n\n\n## Introduction\n\nRecently, there's been a lot of talk about meta-analysis, and here I would just like to quickly show that Bayesian multilevel modeling nicely takes care of your meta-analysis needs, and that it is easy to do in R with the rstan and brms packages. As you'll see, meta-analysis is a special case of Bayesian multilevel modeling when you are unable or unwilling to put a prior distribution on the meta-analytic effect size estimate.\n\nThe idea for this post came from Wolfgang Viechtbauer's [website](http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer?s%5B%5D=lme4), where he compared results for meta-analytic models fitted with his great (frequentist) package [metafor](http://www.metafor-project.org/doku.php/metafor) and the swiss army knife of multilevel modeling, [lme4](https://cran.r-project.org/web/packages/lme4/index.html). It turns out that even though you can fit meta-analytic models with lme4, the results are slightly different from traditional meta-analytic models, because the experiment-wise variances are treated slightly differently.\n\nHere are the packages we'll use:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/packages_43e326fa66c64602900a71de6b7ef011'}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(metafor)\nlibrary(scales)\nlibrary(lme4)\nlibrary(brms)\nlibrary(tidyverse)\n```\n:::\n\n\n## The data\n\nHere I'll only focus on a simple random effects meta-analysis of effect sizes, and will use the same example data as in the aforementioned [website](http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer?s%5B%5D=lme4). The data are included in the metafor package, and describe the relationship between conscientiousness and medication adherence. The effect sizes are r to z transformed correlations.\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/obtain-data_9e42636206d53c6d8aeef44b86a913d1'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/display-fake-data_7319afe6b279a26ee1374c3d0f0fa4d8'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Example data (dat.molloy2014 in metafor package).</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> study </th>\n   <th style=\"text-align:right;\"> year </th>\n   <th style=\"text-align:right;\"> ni </th>\n   <th style=\"text-align:right;\"> ri </th>\n   <th style=\"text-align:right;\"> yi </th>\n   <th style=\"text-align:right;\"> vi </th>\n   <th style=\"text-align:right;\"> sei </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Axelsson et al. (2009) </td>\n   <td style=\"text-align:right;\"> 2009 </td>\n   <td style=\"text-align:right;\"> 109 </td>\n   <td style=\"text-align:right;\"> 0.19 </td>\n   <td style=\"text-align:right;\"> 0.19 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Axelsson et al. (2011) </td>\n   <td style=\"text-align:right;\"> 2011 </td>\n   <td style=\"text-align:right;\"> 749 </td>\n   <td style=\"text-align:right;\"> 0.16 </td>\n   <td style=\"text-align:right;\"> 0.16 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Bruce et al. (2010) </td>\n   <td style=\"text-align:right;\"> 2010 </td>\n   <td style=\"text-align:right;\"> 55 </td>\n   <td style=\"text-align:right;\"> 0.34 </td>\n   <td style=\"text-align:right;\"> 0.35 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Christensen et al. (1995) </td>\n   <td style=\"text-align:right;\"> 1995 </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\"> 0.27 </td>\n   <td style=\"text-align:right;\"> 0.28 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.12 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Christensen et al. (1999) </td>\n   <td style=\"text-align:right;\"> 1999 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n   <td style=\"text-align:right;\"> 0.32 </td>\n   <td style=\"text-align:right;\"> 0.33 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Cohen et al. (2004) </td>\n   <td style=\"text-align:right;\"> 2004 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.13 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Dobbels et al. (2005) </td>\n   <td style=\"text-align:right;\"> 2005 </td>\n   <td style=\"text-align:right;\"> 174 </td>\n   <td style=\"text-align:right;\"> 0.17 </td>\n   <td style=\"text-align:right;\"> 0.18 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Ediger et al. (2007) </td>\n   <td style=\"text-align:right;\"> 2007 </td>\n   <td style=\"text-align:right;\"> 326 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Insel et al. (2006) </td>\n   <td style=\"text-align:right;\"> 2006 </td>\n   <td style=\"text-align:right;\"> 58 </td>\n   <td style=\"text-align:right;\"> 0.26 </td>\n   <td style=\"text-align:right;\"> 0.27 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.13 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Jerant et al. (2011) </td>\n   <td style=\"text-align:right;\"> 2011 </td>\n   <td style=\"text-align:right;\"> 771 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Moran et al. (1997) </td>\n   <td style=\"text-align:right;\"> 1997 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> -0.09 </td>\n   <td style=\"text-align:right;\"> -0.09 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> O'Cleirigh et al. (2007) </td>\n   <td style=\"text-align:right;\"> 2007 </td>\n   <td style=\"text-align:right;\"> 91 </td>\n   <td style=\"text-align:right;\"> 0.37 </td>\n   <td style=\"text-align:right;\"> 0.39 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.11 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Penedo et al. (2003) </td>\n   <td style=\"text-align:right;\"> 2003 </td>\n   <td style=\"text-align:right;\"> 116 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Quine et al. (2012) </td>\n   <td style=\"text-align:right;\"> 2012 </td>\n   <td style=\"text-align:right;\"> 537 </td>\n   <td style=\"text-align:right;\"> 0.15 </td>\n   <td style=\"text-align:right;\"> 0.15 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Stilley et al. (2004) </td>\n   <td style=\"text-align:right;\"> 2004 </td>\n   <td style=\"text-align:right;\"> 158 </td>\n   <td style=\"text-align:right;\"> 0.24 </td>\n   <td style=\"text-align:right;\"> 0.24 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Wiebe &amp; Christensen (1997) </td>\n   <td style=\"text-align:right;\"> 1997 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.13 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## The model\n\nWe are going to fit a random-effects meta-analysis model to these observed effect sizes and their standard errors. Here's what this model looks like, loosely following notation from the R package Metafor's manual (p.6):\n\n\n$$y_i \\sim N(\\theta_i, \\sigma_i^2)$$\n\n\nwhere each recorded effect size, $y_i$ is a draw from a normal distribution which is centered on that study's \"true\" effect size $\\theta_i$ and has standard deviation equal to the study's observed standard error $\\sigma_i$.\n\nOur next set of assumptions is that the studies' true effect sizes approximate some underlying effect size in the (hypothetical) population of all studies. We call this underlying population effect size $\\mu$, and its standard deviation $\\tau$, such that the true effect sizes are thus distributed:\n\n\n$$\\theta_i \\sim N(\\mu, \\tau^2)$$\n\n\nWe now have two interesting parameters: $\\mu$ tells us, all else being equal, what I may expect the \"true\" effect to be, in the population of similar studies. $\\tau$ tells us how much individual studies of this effect vary.\n\nI think it is most straightforward to write this model as yet another mixed-effects model (metafor manual p.6):\n\n\n$$y_i \\sim N(\\mu + \\theta_i, \\sigma^2_i)$$\n\n\nwhere $\\theta_i \\sim N(0, \\tau^2)$, studies' true effects are normally distributed with between-study heterogeneity $\\tau^2$. The reason this is a little confusing (to me at least), is that we know the $\\sigma_i$s (this being the fact that separates meta-analysis from other more common regression modeling).\n\n### Estimation with metafor\n\nSuper easy!\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/unnamed-chunk-1_8de6250d974b12b734b525f2a7880a47'}\n\n```{.r .cell-code}\nlibrary(metafor)\nma_out <- rma(data = dat, yi = yi, sei = sei, slab = dat$study)\nsummary(ma_out)\n## \n## Random-Effects Model (k = 16; tau^2 estimator: REML)\n## \n##   logLik  deviance       AIC       BIC      AICc  ​ \n##   8.6096  -17.2191  -13.2191  -11.8030  -12.2191   \n## \n## tau^2 (estimated amount of total heterogeneity): 0.0081 (SE = 0.0055)\n## tau (square root of estimated tau^2 value):      0.0901\n## I^2 (total heterogeneity / total variability):   61.73%\n## H^2 (total variability / sampling variability):  2.61\n## \n## Test for Heterogeneity:\n## Q(df = 15) = 38.1595, p-val = 0.0009\n## \n## Model Results:\n## \n## estimate      se    zval    pval   ci.lb   ci.ub     ​ \n##   0.1499  0.0316  4.7501  <.0001  0.0881  0.2118  *** \n## \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## Bayesian estimation\n\nSo far so good, we're strictly in the realm of standard meta-analysis. But I would like to propose that instead of using custom meta-analysis software, we simply consider the above model as just another regression model, and fit it like we would any other (multilevel) regression model. That is, using [Stan](http://mc-stan.org/), usually through the [brms](https://cran.r-project.org/package=brms) interface. Going Bayesian allows us to assign prior distributions on the population-level parameters $\\mu$ and $\\tau$, and we would usually want to use some very mildly regularizing priors. Here we proceed with brms' default priors (which I print below with the output)\n\n### Estimation with brms\n\nHere's how to fit this model with brms:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/fit-ma-brms_a697bad10c015e4f6f661029504bf246'}\n\n```{.r .cell-code}\nbrm_out <- brm(\n  yi | se(sei) ~ 1 + (1 | study), \n  data = dat, \n  cores = 4,\n  file = \"metaanalysismodel\"\n)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/results-disp_eba04825fdc1e5e076ce884587958839'}\n\n```\n##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: yi | se(sei) ~ 1 + (1 | study) \n##    Data: dat (Number of observations: 16) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Priors: \n## Intercept ~ student_t(3, 0.2, 2.5)\n## <lower=0> sd ~ student_t(3, 0, 2.5)\n## \n## Group-Level Effects: \n## ~study (Number of levels: 16) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)     0.10      0.04     0.04     0.20 1.00     1256     1887\n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept     0.15      0.04     0.08     0.22 1.00     1957     1884\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     0.00      0.00     0.00     0.00   NA       NA       NA\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nThese results are the same as the ones obtained with metafor. Note the Student's *t* prior distributions, which are diffuse enough not to exert influence on the posterior distribution.\n\n## Comparing results\n\nWe can now compare the results of these two estimation methods. Of course, the Bayesian method has a tremendous advantage, because it results in a full distribution of plausible values.\n\n\n::: {.cell layout-align=\"center\" preview='true' hash='index_cache/html/unnamed-chunk-2_81877cd9b64032094068d926ebc097f9'}\n::: {.cell-output-display}\n![Histogram of samples from the posterior distribution of the average effect size (top left) and the variability (top right). Bottom left displays the multivariate posterior distribution of the average (x-axis) and the standard deviation (y-axis), light colors indicating increased plausibility of values. For each plot, the dashed lines display the maximum likelihood point estimate, and 95% confidence limits (only the point estimate is displayed for the multivariate figure.)](index_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWe can see from the numeric output, and especially the figures, that these modes of inference yield the same numerical results. Keep in mind though, that the Bayesian estimates actually allow you to discuss probabilities, and generally the things that we'd like to discuss when talking about results.\n\nFor example, what is the probability that the average effect size is greater than 0.2? About eight percent:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/unnamed-chunk-3_ea0fd8b7960792f1a1972b30dabad773'}\n\n```{.r .cell-code}\nhypothesis(brm_out, \"Intercept > 0.2\")\n## Hypothesis Tests for class b:\n##              Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n## 1 (Intercept)-(0.2) > 0    -0.05      0.04    -0.11     0.01       0.08      0.08     \n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities.\n```\n:::\n\n\n### Forest plot\n\nThe forest plot displays the entire posterior distribution of each $\\theta_i$. The meta-analytic effect size $\\mu$ is also displayed in the bottom row. I'll show a considerable amount of code here so that you can create your own forest plots from brms output:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/draw-forest-plot_c844276a86710c6650f9b1ff4e93672b'}\n\n```{.r .cell-code}\nlibrary(tidybayes)\nlibrary(ggdist)\n# Study-specific effects are deviations + average\nout_r <- spread_draws(brm_out, r_study[study,term], b_Intercept) %>% \n  mutate(b_Intercept = r_study + b_Intercept) \n# Average effect\nout_f <- spread_draws(brm_out, b_Intercept) %>% \n  mutate(study = \"Average\")\n# Combine average and study-specific effects' data frames\nout_all <- bind_rows(out_r, out_f) %>% \n  ungroup() %>%\n  # Ensure that Average effect is on the bottom of the forest plot\n  mutate(study = fct_relevel(study, \"Average\")) %>% \n  # tidybayes garbles names so fix here\n  mutate(study = str_replace_all(study, \"\\\\.\", \" \"))\n# Data frame of summary numbers\nout_all_sum <- group_by(out_all, study) %>% \n  mean_qi(b_Intercept)\n# Draw plot\nout_all %>%   \n  ggplot(aes(b_Intercept, study)) +\n  # Zero!\n  geom_vline(xintercept = 0, size = .25, lty = 2) +\n  stat_halfeye(.width = c(.8, .95), fill = \"dodgerblue\") +\n  # Add text labels\n  geom_text(\n    data = mutate_if(out_all_sum, is.numeric, round, 2),\n    aes(label = str_glue(\"{b_Intercept} [{.lower}, {.upper}]\"), x = 0.75),\n    hjust = \"inward\"\n  ) +\n  # Observed as empty points\n  geom_point(\n    data = dat %>% mutate(study = str_replace_all(study, \"\\\\.\", \" \")), \n    aes(x=yi), position = position_nudge(y = -.2), shape = 1 \n  )\n```\n\n::: {.cell-output-display}\n![Forest plot of the example model's results. Filled points and intervals are posterior means and 80/95% Credible Intervals. Empty points are observed effect sizes.](index_files/figure-html/draw-forest-plot-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nFocus on Moran et al. (1997)'s observed effect size (the empty circle): This is an anomalous result compared to all other studies. One might describe it as *incredible*, and that is indeed what the bayesian estimation procedure has done, and the resulting posterior distribution is no longer equivalent to the observed effect size. Instead, it is shrunken toward the average effect size. Now look at the table above, this study only had 56 participants, so we should be more skeptical of this study's observed ES, and perhaps we should then adjust our beliefs about this study in the context of other studies. Therefore, our best guess about this study's effect size, given all the other studies is no longer the observed mean, but something closer to the average across the studies.\n\nIf this shrinkage business seems radical, consider Quine et al. (2012). This study had a much greater sample size (537), and therefore a smaller SE. It was also generally more in line with the average effect size estimate. Therefore, the observed mean ES and the mean of the posterior distribution are pretty much identical. This is also a fairly desirable feature.\n\n## Discussion\n\nThe way these different methods are presented (regression, meta-analysis, ANOVA, ...), it is quite easy for a beginner, like me, to lose sight of the forest for the trees. I also feel that this is a general experience for students of applied statistics: Every experiment, situation, and question results in a different statistical method (or worse: \"Which test should I use?\"), and the student doesn't see how the methods relate to each other. So I think focusing on the (regression) model is key, but often overlooked in favor of this sort of decision tree model of choosing statistical methods [@mcelreathStatisticalRethinkingBayesian2020].\n\nAccordingly, I think we've ended up in a situation where meta-analysis, for example, is seen as somehow separate from all the other modeling we do, such as repeated measures t-tests. In fact I think applied statistics in Psychology may too often appear as an unconnected bunch of tricks and models, leading to confusion and inefficient implementation of appropriate methods.\n\n### Bayesian multilevel modeling\n\nAs I've been learning more about statistics, I've often noticed that some technique, applied in a specific set of situations, turns out to be a special case of a more general modeling approach. I'll call this approach here *Bayesian multilevel modeling* [@mcelreathStatisticalRethinkingBayesian2020]. If you are forced to choose one statistical method to learn, it should be Bayesian multilevel modeling, because it allows you to do and understand most things, and allows you to see how similar all these methods are, under the hood.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}